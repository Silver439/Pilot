%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%	Author Submission Template for Operations Research (OPRE)
%%	INFORMS, <informs@informs.org>
%%	Ver. 1.00, June 2024
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Use dblanonrev for Double Anonymous Review submission
% Use sglanonrev for Single Anonymous Review submission
% For example, submission to INFORMS Mathematics of Operation Research, MOOR will have
% \documentclass[moor,dblanonrev]{informs4}
%
% \documentclass[opre,dblanonrev]{informs4}
\documentclass[opre,sglanonrev]{informs4}
\usepackage{eqndefns-left} % For checking the display equation width and equation environment definitions %
\RequirePackage{tgtermes}
\RequirePackage{newtxtext}
\RequirePackage{newtxmath}
\RequirePackage{bm}
\RequirePackage{endnotes}

%\OneAndAHalfSpacedXI
\OneAndAHalfSpacedXII % Current default line spacing
%%\DoubleSpacedXI
%%\DoubleSpacedXII

% Optional LaTeX Packages
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{tikz}
% Private macros here (check that there is no clash with the style)

% Natbib setup for author-number style
\usepackage{natbib}
 \bibpunct[, ]{(}{)}{,}{a}{}{,}%
 \def\bibfont{\small}%
 \def\bibsep{\smallskipamount}%
 \def\bibhang{24pt}%
 \def\newblock{\ }%
 \def\BIBand{and}%


%% Setup of the equation numbering system. Outcomment only one.
%% Preferred default is the first option.
\EquationsNumberedThrough    % Default: (1), (2), ...
%\EquationsNumberedBySection % (1.1), (1.2), ...

%% Setup of theorem styles. Outcomment only one.
%% Preferred default is the first option.
\TheoremsNumberedThrough     % Preferred (Theorem 1, Lemma 1, Theorem 2)
%\TheoremsNumberedByChapter  % (Theorem 1.1, Lema 1.1, Theorem 1.2)
\ECRepeatTheorems  %  

% For new submissions, leave this number blank.
% For revisions, input the manuscript number assigned by the on-line
% system along with a suffix ".Rx" where x is the revision number.
\MANUSCRIPTNO{MOOR-0001-2024.00}

%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%

\RUNTITLE{Module design for pilots training with full flight simulator}

\TITLE{Module Design for Pilots Training with Full Flight Simulator}



\ABSTRACT{
	This study addresses a practical problem in the design of training modules for pilots with Full Flight Simulators (FFS), using operations research techniques. FFSs are highly precise tools that accurately replicate real-world flight scenarios, making them indispensable for pilot training and evaluation. Given their high cost and limited availability, airlines must strategically design modules for pilots’ periodic recurrent assessments. To enhance aviation safety, we formulate a combinatorial optimization objective function to select a set of modules that minimizes a pilot’s lowest score, enabling early detection of potential weaknesses. Our research underscores the importance of accounting for correlations in pilots’ performance across modules. To this end, we develop a suite of optimization methods and provide corresponding managerial insights. Extensive experimental evaluations demonstrate that our approach significantly outperforms traditional methods reliant on intuition and experience.
}% 
\FUNDING{This research was supported by [grant number, funding agency].}

%Supplemental Material:
%Data Ethics & Reproducibility Note:

% Sample
\KEYWORDS{module design, Full Flight Simulators, simulation optimization}

\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Text of your paper here

\section{Background}
% Introducing the Full Flight Simulator
The Full Flight Simulator (FFS) is a highly sophisticated flight training device designed to replicate the cockpit environment and operational dynamics of a specific aircraft model with exceptional fidelity \citep{ICAO2015}. 
%Typically mounted on a six-degree-of-freedom hydraulic motion platform, the FFS 
It is capable of simulating the entire spectrum of flight operations, from takeoff and cruise to landing, encompassing both routine procedures and complex scenarios such as engine failures, hydraulic system malfunctions, severe weather conditions, and even rare events like bird strikes or runway contamination \citep{Advancements2024}. The simulation integrates visual, auditory, and tactile feedback, alongside precise instrument readouts and control responses, to provide an immersive experience that closely mirrors actual flight conditions. Certified to the highest standards, such as Level D by aviation authorities like the Federal Aviation Administration (FAA) or the European Union Aviation Safety Agency (EASA), the FFS achieves unparalleled precision, enabling zero flight time training where pilots can qualify without operating an actual aircraft \citep{FAA1995,EASA2020}. However, this extraordinary accuracy comes at a significant cost, with a single FFS unit priced in the tens of millions of dollars, rendering its manufacture and maintenance a substantial financial commitment \citep{CAE7000XR}. Most airlines typically own only a limited number of FFS units outright or instead lease them from manufacturers such as CAE or L3Harris and dedicated flight training centers \citep{IBAAero2023}.

% Explaining the role in pilot training
The primary application of the FFS lies in pilot training and qualification maintenance, with a particular emphasis on mandatory recurrent training to renew licenses. Pursuant to regulations set by the International Civil Aviation Organization (ICAO) and national aviation authorities, pilots are required to undergo recurrent training every six to twelve months, typically conducted in an FFS, to validate their proficiency \citep{Flightradar2024}.

During qualification assessments, pilots are evaluated through a series of subjects designed to test their ability to manage diverse operational challenges. These subjects are carefully crafted based on real-world flight data and historical incident analyses%, ensuring relevance to actual flight conditions 
\citep{NTSB2012}. Common subjects include ``Engine Failure on Takeoff,'' where pilots must stabilize the aircraft and execute a safe return to the airport following an engine malfunction immediately after liftoff; ``Low Visibility Approach,'' which tests precision navigation and landing in simulated adverse weather; and ``Emergency Descent and Decompression,'' requiring rapid altitude reduction and oxygen management in response to cabin pressure loss \citep{PilotWorkshops2023}. These assessments, which may span several hours, evaluate technical proficiency, decision-making speed, and crew coordination. Successful completion of these subjects results in license renewal, while deficiencies necessitate further training, ensuring consistent competency across the pilot workforce \citep{EASA2020}.

Given the high cost of FFS and the critical need for regular pilot assessments, airlines must carefully balance budgetary constraints with the demand for efficient and effective evaluations. However, the current practice of selecting assessment subjects is often random or reliant on airlines' experiential judgment, which can fail to identify specific deficiencies or redundantly evaluate areas of established proficiency. This work aims to develop dedicated optimization approaches to enhance the selection of assessment subjects, maximizing the effectiveness of the evaluation process.

Suppose there is a pool of $M$ different training modules from which $m$ are selected in one training session due to cost restriction. Ideally, these $m$ subjects should collectively cover a diverse range of skills to efficiently identify a pilot’s weaknesses. 

Unlike conventional approaches, our strategy incorporates the correlations and variability in pilot performance across these modules, driven by individual differences in skills such as hand-eye coordination, spatial awareness, and stress resilience. For instance, pilots with strong coordination skills often excel in subjects like ``Precision Approach'' and ``Instrument Flying,'' as both require similar competencies, including accurate interpretation of flight instruments, stable aircraft control, and anticipation of spatial positioning \citep{Damos2003}. As a result, high performance in one module frequently predicts success in the other due to shared skill requirements. Conversely, pilots with superior stress management capabilities may outperform in complex emergency scenarios such as ``Multi-Engine Failure'', but struggle in subjects like ``Crosswind Landing'' if their coordination is less developed \citep{Szczepanska2025}. These correlations arise from overlapping skill sets and selecting multiple highly correlated subjects may lead to redundant testing.%, as pilots who excel or struggle in one are likely to perform similarly in the others. 
 Accounting for these correlations is therefore critical in optimizing the selection of assessment modules to enhance training efficiency and safety \citep{Duruaku2024}. 

We illustrate this with a simple example, where we need to select two subjects out of three for a pilot's assessment. From an aviation safety perspective, we aim to select the two subjects that best identify the subject with the lowest score, and thus the assessment metric is the minimum score of the two selected subjects. From an optimization perspective, the following objective function is considered   :
$$
	\min_{x_1,x_2} \mathbb{E}[\min\{Y(x_1),...,Y(x_2) \} ], 
	\label{example}
$$
where $x_1,x_2$ are two selected subjects from the subjects pool $\{A,B,C\}$ and $Y(x_i)$ is the score on $x_i$. The scores of each pilot on these three subjects follow a discrete distribution with three scenarios (shown in Table \ref{tab:example}), each with probability 1/3.
\begin{table}[ht]
	\centering
	\caption{Discrete distribution of the scores}
	\label{tab:example}
	\begin{tabular}{cccc} 
		Scenario & A score & B score & C score \\ \hline 
		1 & 9 & 9.5 & 7.5\\
		2 & 6 & 5 & 8\\
		3 & 10 & 9.5 & 10\\
		Expectation & 8.33 & 8 & 8.5\\
	\end{tabular}
\end{table}
From the table, we can observe that the correlation between scores for subjects A and B is significantly higher than that between A and C or B and C, due to the differing skill requirements for the subjects, as previously discussed. If correlations are ignored, the first two subjects might be chosen (due to their lower mean scores). However, calculations reveal that the latter two subjects should be selected. This is precisely because their lower correlation allows them to more independently yield lower scores, increasing the likelihood of identifying the pilot’s weakest performance. Therefore, we need to design an optimization method that fully accounts for the correlations between scores of different subjects.

Addressing this problem presents multiple challenges. First, computing the expected minimum value of several correlated distributions is inherently complex, particularly when selecting an optimal subset of $m$ modules from a larger set to minimize this value. Second, in practical applications, the expected values of these distributions are likely unknown. While we can infer correlations between scores based on the skill requirements of different subjects, estimating the mean scores of pilots across these subjects is considerably more difficult. Hence, an approach that simultaneously learns from data of previous test results and optimizes the selection process is necessary.

To address the first challenge, we assume that the scores follow a multivariate normal distribution (a reasonable model for characterizing examination scores \citep{Ross2014} and has been validated through real-world FFS data). By analyzing the impact of parameters—such as means, variances, and correlations—on the target function, we derive insights to guide module selection. Furthermore, we identify the target function as a submodular problem, enabling the use of a greedy algorithm for approximate computation. To improve computational efficiency, we propose a heuristic algorithm informed by these analytical results. To tackle the second challenge, we develop a combinatorial multi-armed bandit (MAB) algorithm based on a Bayesian framework. This algorithm assigns a prior distribution to the score means, which is continuously updated through iterative testing. In each iteration, an upper confidence bound approach is used to select the module combination to be tested, and we prove the algorithm’s regret bound to ensure its theoretical robustness.

This paper addresses a problem of significant practical relevance, representing an innovative effort to apply optimization and operations research algorithms to real-world challenges. Previously, the design of pilot training modules has relied heavily on intuition and experience. Beyond its practical significance, the optimization problem explored here also carries substantial theoretical value, presenting multiple challenges as outlined earlier. Moreover, while related to existing research domains, it exhibits notable distinctions. Our work primarily aligns with two categories of optimization studies. The first is simulation-based optimization \citep{Fu2015}, which employs simulation models to support decision-making in real-world systems (FFS is a highly precise simulation tool). Certain simulation optimization studies account for correlations in experimental results when selecting multiple design alternatives \citep{xie2016bayesian}. These correlations primarily arise from the use of common random numbers in computer simulations. However, no prior work in this field has targeted the same objective function as ours, as most focus on evaluating a single design’s performance without an internal minimization operation. The second category is combinatorial multi-armed bandit research \citep{Chen2013}, where some studies select multiple alternatives and use the best as the evaluation metric, akin to our objective function \eqref{example}. Yet, to the best of our knowledge, none have addressed correlations among alternatives. These correlations significantly complicate the problem while offering unique managerial insights.

The remainder of the paper is organized as follows. Section \ref{related works} reviews the related works. Section \ref{problem formulation} formulates the objective function. Section \ref{know means} offers some insights and heuristic algorithms for scenarios where expectations are known. Section \ref{unknown means} presents an algorithm that learns expectations during the optimization process, supported by theoretical guarantees. Section 6 reports numerical experiments. Finally, Section 7 concludes the paper.

\section{Related works}
\label{related works}
We review relevant works in three aspects: existing approaches for pilot training modules design, simulation-based optimization, and combinatorial MAB.

\section{Problem Formulation}
\label{problem formulation}
Our goal is to efficiently identify pilots’ deficiencies through rational module design, with these deficiencies measured by their scores during the module evaluation process. Suppose there are $M$ different training modules from which $m$ are selected in one training session due to the time and cost restriction. Then, we select $m$ modules to maximally expose a pilot’s deficiencies, such that the minimum score across these $m$ modules is as low as possible. The optimization problem can be formulated as follows:
\begin{equation}
	\min_{x_1,...,x_m} \mathbb{E}_\xi[\min\{Y(x_1,\xi),...,Y(x_m,\xi) \} ], 
	\label{obj}
\end{equation}
where $x_1,...,x_m$ represent the $m$ modules in the training session, taken from the module set $\mathcal{X} = \{x_1,...,x_M\}$, and $Y(x_1,\xi)$ is the score the pilot obtain in module $x_i$. It is evaluated through simulation at FFS. In this model, we assume the score vector in the population $\{Y(x_1),...,Y(x_M)\}$ follows a multivariate normal distribution. For each specific person, his score is a sample from this distribution. In equation \eqref{obj}, the random vector $\xi$ is used to illustrate the randomness in this multivariate normal distribution. The inner minimization is to find the minimum score one pilot obtain across the given $m$ training modules. We take the minimum value as we need to find the weakness of the pilots considering flight safety. The outer minimization is the find the best set of training sessions in detecting the pilot inadequacy.

\section{Insights and Algorithm with Known Score Means}
\label{know means}
We first consider an ideal scenario for solving Problem \eqref{obj}, where all parameters of the score distributions for all modules are fully known. That is, we aim to select a limited number of dimensions from a completely known multivariate normal distribution such that the expected value of the minimum score across these dimensions is minimized. It should be noted that, in general, this objective function cannot be simplified into a more computationally convenient form. Existing studies provide closed-form solutions for the expected minimum of two normal distributions \citep{nadarajah2008exact}. However, for more than two normal distributions, prior research remains limited. \cite{clark1961greatest} relied on numerical approximation, that recursively applies a three-variate formula, to compute the expected value of their minimum and has analyzed the accuracy of these approximations through numerical validation. Such computational methods are time-consuming, particularly in our optimization scenario, where we need to repeatedly select $m$ modules and compute the expected value of their minimum scores. Therefore, we aim to derive managerial insights from simple, analytically tractable examples and leverage these insights to develop efficient heuristic methods. This section is divided into two parts: in Section \ref{insights}, we use two simplified examples to obtain managerial insights; in Section \ref{submodular}, we demonstrate that the objective function is submodular, enabling the use of a greedy algorithm to achieve an efficient and theoretically guaranteed approximation; in Section \ref{heuristic}, we utilize these insights to develop an efficient heuristic method based on greedy approach.

\subsection{Insights from two simple examples}
\label{insights}
This subsection examines two simplified examples to investigate how parameters in a multivariate normal distribution—specifically the mean, correlation, and variance—affect the expected minimum value. The examples include a bivariate normal distribution (Section \ref{bivariate normal}) and a multi-variate scenario with same means, variances, and correlations (Section \ref{multi-variate}). Despite their simplicity, the conclusions and insights from these examples align with intuition and are corroborated by subsequent numerical experiments.

\subsubsection{Bivariate normal example}
\label{bivariate normal}

For any two Gaussian random number $X_1\sim N(\mu_1,\sigma^2_1)$, $X_2\sim N(\mu_2,\sigma^2_2)$ with correlation $\rho$, the expectation $\text{E}[\min\{X_1, X_2\}]$ takes the following form \citep{clark1961greatest}:
$$
\text{E}[\min\{X_1, X_2\}] = \mu_1\Phi(\frac{\mu_2-\mu_1}{\theta}) + \mu_2\Phi(\frac{\mu_1-\mu_2}{\theta}) - \theta \phi(\frac{\mu_2-\mu_1}{\theta} ),
$$
where $\phi$, $\Phi$ are cdf and pdf for standard normal distribution, respectively, and $\theta = \sqrt{\sigma^2_1+\sigma^2_2-2\rho \sigma_1\sigma_2} = \sqrt{\text{var}(X_1-X_2)}$.

Denote $f=\text{E}[\min\{X_1, X_2\}] $. We have:
\begin{equation}
	\frac{\partial f}{\partial \theta} = -\phi(\frac{\mu_2-\mu_1}{\theta})<0,
\end{equation}
\begin{equation}
	\label{rho}
	\frac{\partial f}{\partial \rho} = \frac{\partial f}{\partial \theta} \frac{\partial \theta}{\partial \rho} =  \frac{\sigma_1\sigma_2}{\theta}\phi(\frac{\mu_2-\mu_1}{\theta})>0,
\end{equation}
\begin{equation}
	\label{sigma}
	\frac{\partial f}{\partial \sigma_1} = \frac{\partial f}{\partial \theta} \frac{\partial \theta}{\partial \sigma_1} = -\frac{\sigma_1-\rho\sigma_2}{\theta} \phi(\frac{\mu_2-\mu_1}{\theta}),
\end{equation}
\begin{equation}
	\label{mu}
	\frac{\partial f}{\partial \mu_1} = \Phi( \frac{\mu_2-\mu_1}{\theta})>0.
\end{equation}

We summarize the conclusions is the following lemma:
\begin{lemma}
	In the bivariate normal example, the expectation of the minimum value is smaller when the two variables have smaller expectations and correlations.
\end{lemma}

The relation between $f$ and the variance for each individual variable is not monotone. We can, however, derive some special cases:
	\begin{enumerate}
		\item When $\rho<\frac{\sigma_1}{\sigma_2}$ (specifically when $\rho<0$), a larger value of $\sigma_1$ is preferred.
		\item When $\rho>\frac{\sigma_1}{\sigma_2}$, smaller value of $\sigma_1$ is preferred. This result may appear counter-intuitive. To gain insight, consider a special case where $\rho = 1$ and $\sigma_1<\sigma_2$. In this scenario, $X_1$ and $X_2$ are positively linear dependent, with $ X_1 = \frac{\sigma_1}{\sigma_2} X_2$. Consequently, $X_1$ and $X_2$ always share the same sign. When $X_1, X_2 > 0$, the minimum is $\min\{X_1, X_2\} = X_1 > 0$, which increases with $\sigma_1$. When $X_1, X_2 < 0$, the minimum is $\min\{X_1, X_2\} = X_2 < 0$, which is independent of $\sigma_1$. Thus, a larger $\sigma_1$ increases the objective function value in this case. Although a larger $\sigma_1$ reduces $X_1$ when negative, these negative values do not contribute to the objective function as long as $\sigma_1 < \sigma_2$. This effect diminishes slightly as $\rho$ deviates from 1, but negative values of $X_1$ remain less likely to influence the objective function until $\rho < \frac{\sigma_1}{\sigma_2}$.
	\end{enumerate}


\subsubsection{Multi-variate normal example}
\label{multi-variate}

We consider the following scenario: $m$ normal random numbers $X_1,...,X_m$ with equal mean $\mu$ and equal variance $\sigma^2$. The correlation between each pair of variables is $\rho\geq 0$. We would like to explore the relationship between the objective function  $f = \text{E}[\min\{X_1,...,X_m\}]$ and $\rho$, $\mu$, and $\sigma$.

In this case, each random variable can be represented as $X_i = \mu + \sigma(\sqrt{\rho}W + \sqrt{1-\rho} N_i )$, where $W$ and $N_1,...,N_m$ are i.i.d. standard normal random variables. Then,
$$f = \text{E}[\min\{X_1,...,X_m\}] =  \text{E}[\min\{\mu + \sigma(\sqrt{\rho}W + \sqrt{1-\rho} N_1 ),...,\mu + \sigma(\sqrt{\rho}W + \sqrt{1-\rho} N_m )\}] $$
$$=\mu+ \sigma\text{E}[\min\{\sqrt{\rho}W + \sqrt{1-\rho} N_1 ,...,\sqrt{\rho}W + \sqrt{1-\rho} N_m \}]  $$
$$=\mu + \sigma\text{E}[\sqrt{\rho}W+ \sqrt{1-\rho} \min\{N_1,...,N_m\} ] =\mu + \sigma\sqrt{1-\rho} \text{E}[\min\{N_1,...,N_m\} ]. $$

Noted that $\text{E}[\min\{N_1 ,...,N_m \}]$ is a constant for a given $m$. It is negative and can be approximated as 
$$-\sqrt{2 \ln m} + \frac{\ln \ln m + \ln 4\pi}{ 2 \sqrt{2 \ln m}}. $$
Hence, $f\approx \mu - \sigma\sqrt{1-\rho}\sqrt{2 \ln m}$. 

We summarize the insights from this example in the following lemma.

\begin{lemma}
	In the simple multi-variate normal example, the expectation of the minimum value is smaller with smaller $\mu$, larger $\sigma$ or smaller $\rho$.
\end{lemma}

For a general multi-variate normal distribution, analyzing the impact of the covariance matrix on the objective function $   f   $ using simple algebra is challenging. However, we can derive the following lemma regarding the influence of the means.
\begin{lemma}
	In a general multi-variate normal distribution, if the covariance matrix is fixed, the value of $f$ reduces if the mean vector gets smaller pointwisely.
\end{lemma}

We summarize the managerial insights derived from these examples for decision-making as follows. To achieve a smaller value for the objective function, we should generally select: 
\begin{enumerate}
	\item $m$ Gaussian variables with smaller means;
	\item variables with lower correlations;
	\item variables with larger variances.
\end{enumerate}
According to Lemma 3, when other factors remain constant, a smaller mean vector directly reduces the expected minimum value. Furthermore, regarding the other two points, the lower the correlations and the larger the variances of the $m$ variables, the more independently each variable can take potentially smaller values, thereby reducing the minimum value.

%-----------------------------------------------------------------------------------------
\subsection{Demonstration of Submodular Objective Function and Greedy Algorithm}
\label{submodular}

The analytical insights from Section 4.1 provide intuitive guidelines for module selection. In this subsection, we unveil a deeper, more powerful mathematical property of our objective function—submodularity. This property allows us to tackle the complex combinatorial optimization problem using a greedy algorithm with a provable performance guarantee.

We first recall the definition of submodularity. For a finite set $\mathcal{V}$ (the set of all training modules $\mathcal{X}$ in our context), a set function $R: 2^{\mathcal{V}} \to \mathbb{R}$ is \textbf{submodular} if it satisfies the diminishing returns property: for any subsets $S \subseteq T \subseteq \mathcal{V}$ and any element $x \in \mathcal{V} \setminus T$,
$$
R(S \cup \{x\}) - R(S) \geq R(T \cup \{x\}) - R(T).
$$
This means the marginal gain of adding a new element $x$ to a set $S$ is at least as large as the marginal gain of adding the same element to a superset $T$ of $S$.

In our problem, we define the set function for a module subset $S \subseteq \mathcal{X}$ as $R(S) = \mathbb{E}[\min\{Y(x) : x \in S\}]$. Our goal is to minimize $R(S)$. To frame this for a greedy algorithm that maximizes a utility, we define a utility function $U(S) = y_{\text{max}}-R(S)$. Here $y_{\text{max}}$ is the maximum score a pilot could achieve on any module. Then we give the following theorem:

\begin{theorem}
\label{thm:submodular}
Given that the module score vector $\mathbf{Y} = (Y(x_1,\xi),...,Y(x_m,\xi))$ follows a multivariate normal distribution $\mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\Sigma})$. For $S \subseteq \mathcal{X}$, the set function $U(S) = y_{\text{max}}-R(S) = y_{\text{max}}-\mathbb{E}[\min\{Y(x) : x \in S\}]$ is:
\begin{enumerate}
    \item \textbf{Monotone Increasing}: For any $S \subseteq T \subseteq \mathcal{X}$, $U(S) \leq U(T)$.
    \item \textbf{Submodular}: For any $S \subseteq T \subseteq \mathcal{X}$ and any module $x \in \mathcal{X} \setminus T$, $U(S \cup \{x\}) - U(S) \geq U(T \cup \{x\}) - U(T)$.
\end{enumerate}
\end{theorem}
\textit{Proof.} Monotone Increasing is quite obvious. Here we show that $U(\cdot)$ is submodular. i.e., for any $S \subseteq T \subseteq \mathcal{X}$ and $x \in \mathcal{X} \setminus T$:
$$
U(S \cup \{x\}) - U(S) \geq U(T \cup \{x\}) - U(T).
$$
which is equivalent to:
$$
R(S)-R(S \cup \{x\}) \geq R(T) - R(T \cup \{x\}).
$$

Let $Y_S = \min_{i \in S} Y(i,\xi)$, $Y_T = \min_{i \in T} Y(i,\xi)$, $Y_x = Y(x,\xi)$. Then $Y_T \leq Y_S$. We have:
\[
R(S) - R(S \cup \{x\}) = \mathbb{E}\left[Y_S - \min\{Y_S, Y_x\}\right],
\]
\[
R(T) - R(T \cup \{x\}) = \mathbb{E}\left[Y_T - \min\{Y_T, Y_x\}\right].
\]

Consider the function $g(y) = y - \min\{y, x\}$. For fixed $x$:
\begin{itemize}
    \item If $y \leq x$, then $g(y) = 0$;
    \item If $y > x$, then $g(y) = y - x$.
\end{itemize}
Thus, $g(y)$ is non-decreasing in $y$. Since $Y_A \geq Y_B$, we have:
\[
Y_S - \min\{Y_S, Y_x\} \geq Y_T - \min\{Y_T, Y_x\}.
\]
Taking expectation:
\[
\mathbb{E}\left[Y_S - \min\{Y_S, Y_x\}\right] \geq \mathbb{E}\left[Y_T - \min\{Y_T, Y_x\}\right],
\]
which implies:
$$
U(S \cup \{x\}) - U(S) \geq U(T \cup \{x\}) - U(T).
$$
Therefore, $U(\cdot)$ is submodular.\hfill $\blacksquare$


Theorem \ref{thm:submodular} establishes that $U(S)$ is a monotone increasing, submodular function. Therefore, the problem of selecting a set $S$ of size $m$ to maximize $U(S)$ is an instance of maximizing a monotone submodular function under a cardinality constraint.

For this class of problems, the classical greedy algorithm provides a strong approximation guarantee. The algorithm starts with an empty set $S_0 = \emptyset$. At each step $k = 1, ..., m$, it adds the module $x$ that provides the highest marginal gain:
\begin{equation}
x_{k} = \argmax_{x \in \mathcal{X} \setminus S_{k-1}} \left[ U(S_{k-1} \cup \{x\}) - U(S_{k-1}) \right],
\end{equation}
and then updates $S_k = S_{k-1} \cup \{x_k\}$.

\begin{theorem}[\cite{nemhauser1978analysis}]
\label{thm:greedy_guarantee}
Let $S^*$ be the optimal set of size $m$ that maximizes $U(S)$, and let $S^{\text{greedy}}_m$ be the set of size $m$ obtained by the greedy algorithm. If $U$ is a monotone, non-negative, submodular function, then the greedy algorithm achieves the following performance guarantee:
$$
U(S^{\text{greedy}}_m) \geq \left(1 - \frac{1}{e}\right) U(S^*) \approx 0.632 \cdot U(S^*).
$$
This guarantee holds regardless of the order of the modules added after the first optimal choice, making the greedy algorithm highly effective for large-scale problems where exhaustive search is infeasible.
\end{theorem}

This theoretical guarantee is significant. It ensures that even without computing the computationally expensive exact optimal solution, the greedy heuristic yields a solution that is provably within at least approximately 63\% of the optimal value in the worst case. This result justifies the development of greedy-inspired heuristic methods in the next section. Although calculating the exact marginal gain $U(S \cup \{x\}) - U(S)$ for each candidate module $x$ may require numerical integration of the expected minimum (as discussed in Section 4.1), the submodularity property allows us to use the managerial insights derived in Section 4.1—favoring modules with lower means, higher variances, and lower correlations—as effective proxies for the true marginal gain when designing efficient heuristics.
%-----------------------------------------------------------------------------------------
\subsection{Heuristic algorithms}
\label{heuristic}



\section{A Combinatorial MAB Algorithm for Unknown Score Means}
\label{unknown means}
We assume that the score has Gaussian noise: $Y(x) = Z(x) + \mathcal{N}(0,\sigma(x))$ and the joint distribution for $Y(x)_{x\in\{\mathcal{X}\}}$ is a multivariate normal distribution with mean vector $\theta = [Z(x_1),...,Z(x_M)]^T$ and covariance matrix $\Lambda$. We use a Bayesian approach to model $\theta$ and assume a normal prior:
$$\theta \sim \mathcal{N}(\mu_0, \Sigma_0). $$
As with \cite{xie2016bayesian}, we assume $\Lambda, \mu_0, \Sigma_0$ are known.

The $i$th entry of a vector $v$ is denoted as $v(i)$ and the $(i,j)$th entry of a matrix $M$ is denoted as $M(i,j)$. For an ordered collection of $m$ alternatives ${\bf x}=(x_1,...,x_m)$ with element $x_i \in \{1,...,M\}$ for each $i$, we use $v(\bf x)$ to denote the subvector of $v$ with the $i$th entry equal to $v(x_i)$. We further denote by $M(\bf x, x')$ the $m$-by-$m$ submatrix of $M$ with the $(i,j)$th entry equal to $M(x_i, x_j')$.  

We consider a situation where in each iteration $n$, one pilot will attend $m$ different modules ${\bf x}_n = (x_{n,1},...,x_{n,m})^T$ and we obtain his score vector ${\bf y}_n = (Y(x_{n,1}),...,Y(x_{n,m}))^T$. The conditional distribution of ${\bf y}_n$ is:
$${\bf y}_n | \theta,{\bf x}_n \sim \mathcal{N}(\theta({\bf x}_n), \Lambda({\bf x}_n,{\bf x}_n)). $$ 
Let $\mathbb{X}_n = ({\bf x}_1^T,...,{\bf x}_n^T )$ denote the concatenation of the design points of the previous $n$ iteration and similarly $\mathbb{Y}_n =({\bf y}_1^T,...,{\bf y}_n^T )^T$. Then, the posterior distribution for $\theta$ is:
$$\theta_n|\mathbb{X}_n,\mathbb{Y}_n  \sim \mathcal{N}(\mu_n, \Sigma_n),$$
where for any vector ${\bf x} = (x_1, x_2,...,x_m)$,
$$
	\mu_n({\bf x}) = \mu_0({\bf x}) + \Sigma_0(\bf x, \mathbb{X}_n)(\Sigma_0(\mathbb{X}_n,\mathbb{X}_n) + \Gamma_n)^{-1}(\mathbb{Y}_n-\mu_0(\mathbb{X}_n)),
$$
$$
	\Sigma_n({\bf x},{\bf x}) = \Sigma_0({\bf x},{\bf x}) - \Sigma_0(\bf x, \mathbb{X}_n)(\Sigma_0(\mathbb{X}_n,\mathbb{X}_n) + \Gamma_n)^{-1}\Sigma_0(\mathbb{X}_n, \bf x),
$$
where $\Gamma_n$ is the block diagonal matrix with $n$ blocks: $\Lambda({\bf x}_1, {\bf x}_1),...,\Lambda({\bf x}_n, {\bf x}_n)$.

We adopt the Expected Improvement (EI) acquisition function to select the $m$ courses for the next iteration $n+1$. For any candidate vector ${\bf x}=(x_1,...,x_m)$,
$$ 
\text{EI}({\bf x}) = \mathbb{E}_{\theta_n}[(g_c-G({\bf x}))^+ | \theta_n],
$$
where $(a)^+=a$ if $a\geq 0$ and $(a)^+=0$ otherwise. When $\theta_n$ takes a value $\tilde{\theta_n}$, we define $G({\bf x})$ as:
$$
G({\bf x}) = \mathbb{E}_\xi[\min\{Y(x_1,\xi),...,Y(x_m,\xi) \} ],
$$
where $\{Y(x_1),...,Y(x_m)\} \sim \mathcal{N}(\tilde{\theta_n}({\bf x}), \Lambda({\bf x},{\bf x}))$ and $\{Y(x_1,\xi),...,Y(x_m,\xi)\}$ is a random sample from this distribution. In the EI function, $g_c$ is the current best value: $g_c = \min \{G({\bf x}_1),...,G({\bf x}_n)\}$.

We next explain how to compute $g_c$. For any vector ${\bf x}_i, 1\leq i \leq n$, we approximate $G({\bf x}_i)$ through sample average approximation (SAA). Specifically, we generate samples of $\{Y(x_{i,1},\xi),...,Y(x_{i,m},\xi)\}$ from distribution $\mathcal{N}(\mu_n({\bf x}_i), \Lambda({\bf x}_i,{\bf x}_i))$. Here, as we already have observations at ${\bf x}_i$, we use the posterior mean $\mu_n({\bf x}_i)$ as if it were the true value of $\theta_n({\bf x}_i)$ to compute the current best value. Similar approach has been widely used for ordinary stochastic GP based optimization algorithms. The samples can then be generated as follows. Suppose $\Lambda({\bf x}_i,{\bf x}_i) = B_iB_i^T$ and ${\bf z}_j\in \mathbb{R}^{m\times 1}$ is a random draw from $m$ iid standard normal distribution. The $j$-th random samples can be represented as: $(Y(x_{i,1},\xi_j),...,Y(x_{i,m},\xi_j))^T = \mu_n({\bf x}_i) + B_i{\bf z}_j$ and $Y(x_{i,k},\xi_j) = \mu_n({x}_{i,k}) + B_i^k{\bf z}_j$, where $B_i^k$ is the $k$th row of $B_i$. Therefore, we have
$$ 
G({\bf x}_i) \approx \frac{1}{J}\sum_{j=1}^{J} \min \mu_n({\bf x}_i) + B_i{\bf z}_j = \frac{1}{J}\sum_{j=1}^{J} \min \{\mu_n({x}_{i,1}) + B_i^1{\bf z}_j, ...,\mu_n({x}_{i,m}) + B_i^m{\bf z}_j  \}.
$$

To compute EI for ${\bf x}$, we should further take care of the outer expectation with respect to the posterior distribution of $\theta$. We can use similar approach as above the generate samples from the posterior distribution of $\theta_n({\bf x})$ and obtain the following SAA form:
$$
\text{EI}({\bf x}) \approx \frac{1}{K}\sum_{k=1}^{K} (g_c-  \frac{1}{J}\sum_{j=1}^{J} \min \theta_n({\bf x}) + A{\bf \tilde{z}}_k + B{\bf z}_j )^+,
$$ 
where $\Sigma_n({\bf x},{\bf x}) = AA^T$, $\Lambda({\bf x},{\bf x}) = BB^T$, and both ${\bf \tilde{z}}_k$ and ${\bf z}_j$ are iid standard normal vectors of length $m$.

%--------------------------------------------------------------------------------------
\section{Theoretical analysis}
\subsection{Convergence analysis}
\begin{lemma}
For any $\epsilon > 0$ and any $n = T_{i,t-1} \in \mathbb{Z}_+$, we have :
$$
\textnormal{Pr}[|\mu_{t-1}(i)-\mu(i)|\geq \epsilon_i]\leq \exp(-\frac{n\epsilon_i^2}{2\sigma^2(i)})
$$
\end{lemma} 
\textit{Proof.} Fix $t\geq 1$ and $i\in [m]$. Conditioned on $(\mathbf{y}_1,...,\mathbf{y}_{t-1}), \{S_1,...,S_{t-1}\}$ are deterministic, and $\mu(i)\thicksim N(\mu_{t-1}(i),\sigma_{t-1}^2(i))$. Now, if $r\thicksim N(0,1)$,then: 
$$\begin{gathered}
\mathrm{Pr}\{r>c\}
\begin{aligned}
=e^{-c^2/2}(2\pi)^{-1/2}\int e^{-(r-c)^2/2-c(r-c)}dr
\end{aligned} \\
\leq e^{-c^2/2}\Pr\{r>0\}=(1/2)e^{-c^2/2}
\end{gathered}$$
for $c>0$, since $e^{-c(r-c)}\leq 1$ for $r\geq c$. Therefore, $\textnormal{Pr}\{|\mu_{t-1}(i)-\mu(i)|>\lambda_i \sigma_{t-1}(i)\}\leq e^{-\lambda_i/2}$

Assume that arm $i$ has been observed $n$ times, yielding $n$ observations. Further assume that these $n$ observations are our only observational data. Using GP modeling, we obtain:
\[
\sigma_n^2(i) = k(i,i) - \mathbf{k}_n^\top(i)(\mathbf{K}_n + \sigma^2(i)\mathbf{I}_n)^{-1}\mathbf{k}_n(i)
\]
where:
\begin{itemize}
    \item $\mathbf{k}_n(i) = [k(i,i),\dots,k(i,i)]^\top \in \mathbb{R}^n$
    \item $\mathbf{K}_n = \sigma_0^2\mathbf{1}_n\mathbf{1}_n^\top$ ($\sigma_0^2 = k(i,i)$)
\end{itemize} % itemize 已闭合

For $\mathbf{A} = \sigma^2(i)\mathbf{I}_n$, $\mathbf{u} = \sigma_0^2\mathbf{1}_n$, $\mathbf{v} = \mathbf{1}_n$, by \textbf{Sherman-Morrison} formula:
\begin{equation*}
\begin{aligned}
(\mathbf{K}_n + \sigma^2(i)\mathbf{I}_n)^{-1} &= \mathbf{A}^{-1} - \frac{\mathbf{A}^{-1}\mathbf{u}\mathbf{v}^\top\mathbf{A}^{-1}}{1 + \mathbf{v}^\top\mathbf{A}^{-1}\mathbf{u}} \\
&= \frac{1}{\sigma^2(i)}\mathbf{I}_n - \frac{\sigma_0^2/\sigma(i)^4 \cdot \mathbf{1}_n\mathbf{1}_n^\top}{1 + n\sigma_0^2/\sigma^2(i)}
\end{aligned}
\end{equation*} 

So we have:
\[
\mathbf{k}_n^\top(i)(\mathbf{K}_n + \sigma^2(i)\mathbf{I}_n)^{-1}\mathbf{k}_n(i) = \frac{\sigma_0^4n}{\sigma^2(i) + n\sigma_0^2}
\]

Substitute the results into the posterior variance formula:
\begin{equation*}
\begin{aligned}
\sigma_n^2(i) &= \sigma_0^2 - \frac{\sigma_0^4n}{\sigma^2(i) + n\sigma_0^2} = \frac{\sigma_0^2\sigma^2(i)}{\sigma^2(i) + n\sigma_0^2} \\
&= \frac{n\sigma_0^2}{\sigma^2(i)+n\sigma_0^2}\cdot \frac{\sigma^2(i)}{n} \leq \frac{\sigma^2(i)}{n}
\end{aligned}
\end{equation*} 
Considering that adding other observation points will not increase the uncertainty of arm $i$, so we have $\sigma_{t-1}(i) \leq \sigma_n(i) \leq \frac{\sigma(i)}{\sqrt{n}}$. Therefore:

$$\textnormal{Pr}\left\{|\mu_{t-1}(i)-\mu(i)|>\lambda_i \frac{\sigma(i)}{\sqrt{n}}\right\}\leq\textnormal{Pr}\{|\mu_{t-1}(i)-\mu(i)|>\lambda_i \sigma_{t-1}(i)\}\leq e^{-\lambda_i/2}$$
Denote $\epsilon_i = \lambda_i \frac{\sigma(i)}{\sqrt{n}}$, then we have $\textnormal{Pr}[|\mu_{t-1}(i)-\mu(i)|\geq \epsilon_i]\leq \exp(-\frac{n\epsilon_i^2}{2\sigma^2(i)})$  \hfill $\blacksquare$

\begin{lemma}
If for any $i \in [m]$ we have $\mu_1(i) \geq \mu_2(i)$ (Abbreviated as $\boldsymbol{\mu}_1 \geq \boldsymbol{\mu}_2)$, then for any super arm $S \in \mathcal{F}$,we have:
$$
r_{P_1}(S) \geq r_{P_2}(S)
$$	
\end{lemma}

\begin{lemma}
If for any $i \in [m]$ we have $\mu_1(i) - \mu_2(i) \leq \Lambda_i (\Lambda_i>0)$ ($\boldsymbol{\mu}_1 \geq \boldsymbol{\mu}_2$). For any super arm $S \in \mathcal{F}$, let $\Lambda_S = \mathop{\max}\limits_{i\in S}\Lambda_i$, then we have:
$$
r_{P_1}(S) - r_{P_2}(S) \leq \Lambda_S
$$
\end{lemma}
\textit{Proof.} For any super arm $S = \{i_1,...,i_n\}$, denote the corresponding mean vectors in distributions $P_1$ and $P_2$ as $\boldsymbol{\mu}_{1,S} = [\mu_1(i_1),...,\mu_1(i_n)]^T$, $\boldsymbol{\mu}_{2,S} = [\mu_1(i_2),...,\mu_2(i_n)]^T$. Note that $P_1$ and $P_2$ are both multivariate normal distributions, and have same covariance matrices $\Sigma_S$.

Now, let $\mathbf{z} = [z_1,...,z_n]^T \sim N(0,\Sigma_S)$. We have:
$$
r_{P_1}(S) = \idotsint_\mathbf{z} \min \{\mu_1(i_1)+z_1,\mu_1(i_2)+z_2, \dots ,\mu_1(i_n)+z_n\} \,dz_1 \dots dz_k
$$
$$
r_{P_2}(S) = \idotsint_\mathbf{z} \min \{\mu_2(i_1)+z_1,\mu_2(i_2)+z_2, \dots ,\mu_2(i_n)+z_n\} \,dz_1 \dots dz_k
$$

Denote $f(\boldsymbol{\mu}_{1,S}+\mathbf{z}) = \min \{\mu_1(i_1)+z_1,\mu_1(i_2)+z_2, \dots ,\mu_1(i_n)+z_n\}$ and $f(\boldsymbol{\mu}_{2,S}+\mathbf{z}) = \min \{\mu_2(i_1)+z_1,\mu_2(i_2)+z_2, \dots ,\mu_2(i_n)+z_n\}$. We want to show that $f(\mu_{1,S}+\mathbf{z})-f(\mu_{2,S}+\mathbf{z})\leq \Lambda_S$.

If there exists $i,j\in S=\{i_1,...,i_n\}$ s.t. $\mu_1(i)+z_i = f(\mu_{1,S}+\mathbf{z})$, $\mu_2(j)+z_j = f(\mu_{2,S}+\mathbf{z})$, $f(\mu_{1,S}+\mathbf{z})-f(\mu_{2,S}+\mathbf{z})>\Lambda_S$. Since $\mu_1(i)+z_i = f(\mu_{1,S}+\mathbf{z}) = \min \{\mu_1(i_1)+z_1,\mu_1(i_2)+z_2, \dots ,\mu_1(i_n)+z_n\}$, we have: $\mu_1(j)+z_j> \mu_1(i)+z_i$.

Thus $\mu_1(j)-\mu_2(j) = \mu_1(j)+z_j-(\mu_2(j)+z_j)>\mu_1(i)+z_i-(\mu_2(j)+z_j)>\Lambda_S$, which is contradict with $\boldsymbol{\mu}_1 \geq \boldsymbol{\mu}_2$.

Therefore

$$
\begin{aligned}
r_{P_1}(S)-r_{P_2}(S) &= \idotsint_\mathbf{z} f(\boldsymbol{\mu}_{1,S}+\mathbf{z})-f(\boldsymbol{\mu}_{2,S}+\mathbf{z}) \,dz_1 \dots dz_k\\
&\leq \idotsint_\mathbf{z} \Lambda_S \,dz_1 \dots dz_k = \Lambda_S 
\end{aligned}
$$
\hfill $\blacksquare$

\begin{lemma}
Define an event in each round $t(m+1)\leq t \leq T$:
$$
	\mathcal{H}_t = \left\{0<\Delta_{S_t}\leq 2\mathop{\max}\limits_{i\in S_t}\sigma(i)\sqrt{\frac{6\ln(t)}{T_{i,t-1}}}\right\}
$$
Then the $\alpha$-approximation regret in $T$ rounds is at most
$$
	\mathbb{E}[\sum_{t=m+1}^{T}\mathbb{I}\{\mathcal{H}_t\}\Delta_{S_t}] + (\frac{\pi^2}{6}+1)\alpha M m.
$$
\end{lemma}
\textit{Proof.} For each super arm $S$, we define:
$$
\Delta_S = \text{max}\{r_P(S) - \alpha \cdot r_P(S^*), 0 \}
$$

From $m+1\leq t \leq T$, Define an event:
$$
\varepsilon_t = \left\{\text{there exists } i \in [m] \text{ such that } |\hat{\mu}_{T_{i,t-1}}^i-\mu^i| \geq \sigma(i)\sqrt{\frac{6\ln(t)}{T_{i,t-1}}}\right\}
$$

We bound the $\alpha$-approximation regret as:

\begin{equation}
	\begin{aligned}
		  \text{Reg}_{P,\alpha}(T) &= \sum_{t=1}^{T}\mathbb{E}\big[\alpha r_P(S^*) - r_P(S_t)\big]\\
		  &\leq \sum_{t=1}^{T}\mathbb{E}[\Delta_{S_t}]\\
		  &=\mathbb{E}[\sum_{t=1}^{m}\Delta_{S_t}]+\mathbb{E}[\sum_{t=m+1}^{T}\mathbb{I}\{\varepsilon_t\}\Delta_{S_t}]\\
		  &+\mathbb{E}[\sum_{t=m+1}^{T}\mathbb{I}\{\lnot \varepsilon_t\}\Delta_{S_t}]
	\end{aligned}
\end{equation}

(a) the first term 

Let $M  = 100$, The first term can be trivially bounded as:
\begin{equation}
	\mathbb{E}[\sum_{t=1}^{m}\Delta_{S_t}] \leq \sum_{t=1}^{m}\alpha \cdot r_P(S^*) \leq m \cdot \alpha M
\end{equation}

(b) the second term 

By Lemma 1 we know that for any $i \in [m],t\geq m+1$, denote $c_i = \sigma(i)\sqrt{\frac{6\ln(t)}{T_{i,t-1}}}$, we have:
$$
	\text{Pr}[|\hat{\mu}_{t-1}(i)-\mu(i)|\geq c_i] \leq \exp(-\frac{nc_i^2}{2\sigma^2(i)}) = t^{-3}
$$

Therefore
\begin{equation}
	\begin{aligned}
		\mathbb{E}[\sum_{t=m+1}^{T}\mathbb{I}\{\varepsilon_t\}]
		% &\leq \sum_{t=m+1}^{T} \sum_{i=1}^{m} \sum_{l=1}^{t-1}\text{Pr}[|\hat{\mu}_{t-1}(i)-\mu(i)|\geq c_i] \\
		&\leq \sum_{t=m+1}^{T} \sum_{i=1}^{m} \sum_{l=1}^{t-1}t^{-3} \\
		&\leq m \sum_{t=m+1}^{T}t^{-2} \\
		&\leq \frac{\pi^2}{6}m
	\end{aligned}
\end{equation}

and then the second term in (6) can be bounded as
\begin{equation}
	\begin{aligned}
		\mathbb{E}[\sum_{t=m+1}^{T}\mathbb{I}\{\varepsilon_t\}\Delta_{S_t}]\leq \frac{\pi^2}{6}m \cdot (\alpha \cdot r_P(S^*)) \leq \frac{\pi^2}{6}\alpha M m
	\end{aligned}
\end{equation}

(c) the third term 

We fix $t>m$ and first asuume $\lnot \varepsilon_t$ happens. For each $i \in [m]$, since $\lnot \varepsilon_t$ happens, we have:
\begin{equation}
	|\hat{\mu}_{T_{i,t-1}}(i)-\mu(i)| < c_i ~~~ \forall i \in [m]
\end{equation}

Recall that in round $t$, the input to the oracle is $\underline{P} = \mathcal{N}(\underline{\boldsymbol{\mu}},\Sigma)$, where the mean vector of $\underline{P}$ is:
\begin{equation}
	\underline{\mu}(i) = \hat{\mu}(i)-c_i ~~~ \forall i \in [m]
\end{equation}

From (10) and (11) we  konw that $\mu(i)>\underline{\mu}(i)>\mu(i)-2c_i$ for all $i \in [m]$. Thus, from Lemma 2 we have:
\begin{equation}
	r_{\underline{P}}(S)\leq r_P(S) ~~~ \forall S \in \mathcal{F}.
\end{equation}

and from Lemma 3 we have:
\begin{equation}
	r_{\underline{P}}(S)\geq r_P(S)-2\Lambda_S ~~~ \forall S \in \mathcal{F}.
\end{equation}
where $\Lambda = \mathop{\max}\limits_{i}c_i$

Also, from the fact that the algorithm chooses $S_t$ in the t-th round, we have:
\begin{equation}
	r_{\underline{P}}(S_t)\leq \alpha \cdot \mathop{\min}\limits_{S \in \mathcal{F}}r_{\underline{P}}(S) \leq \alpha \cdot r_{\underline{P}}(S^*).
\end{equation}
From (12),(13) and (14) we have:
\begin{equation}
	r_P(S)-2\Lambda_S \leq r_{\underline{P}}(S_t) \leq \alpha \cdot r_{\underline{P}}(S^*) \leq \alpha \cdot r_P(S^*)
\end{equation}

which implies:
$$
	\Delta_{S_t} \leq 2\Lambda_S
$$

Therefore, when $\lnot \varepsilon_t$ happens, we always have $\Delta_{S_t}\leq 2\mathop{\max}\limits_{i\in S_t}c_i$.

This implies:
$$
	\{\lnot \varepsilon_t, \Delta_{S_t}>0\}\Longrightarrow \{0<\Delta_{S_t}\leq 2\mathop{\max}\limits_{i\in S_t}c_i\}=\mathcal{H}_t.
$$

Hence, the third term in (6) can be bounded as:
\begin{equation}
	\begin{aligned}
		\mathbb{E}[\sum_{t=m+1}^{T}\mathbb{I}\{\lnot \varepsilon_t\}\Delta_{S_t}] &= \mathbb{E}[\sum_{t=m+1}^{T}\mathbb{I}\{\lnot \varepsilon_t. \Delta_{S_t}>0\}\Delta_{S_t}]\\
		&\leq \mathbb{E}[\sum_{t=m+1}^{T}\mathbb{I}\{\mathcal{H}_t\}\Delta_{S_t}]
	\end{aligned}
\end{equation}

Finally, by combining (6),(7),(9),(16) we have:
$$
	\text{Reg}_{P,\alpha}(T) \leq \mathbb{E}[\sum_{t=m+1}^{T}\mathbb{I}\{\mathcal{H}_t\}\Delta_{S_t}] + (\frac{\pi^2}{6}+1)\alpha M m
$$
\hfill $\blacksquare$

Now it remains to bound $\mathbb{E}[\sum_{t=m+1}^{T}\mathbb{I}\{\mathcal{H}_t\}\Delta_{S_t}]$.

Define two decreasing sequences of positive contants:
$$\begin{aligned}
1 & =\beta_0>\beta_1>\beta_2>\ldots \\
 & \alpha_1>\alpha_2>\ldots
\end{aligned}$$

such that $\lim_{k \to \infty}\alpha_k = \lim_{k \to \infty}\beta_k=0$. We choose $\{\alpha_k\}$ and $\{\beta_k\}$ as in Theorem 4 of \citep{Kveton2014TightRB}, which satisfy:

\begin{equation}\sqrt{6}\sum_{k=1}^\infty\frac{\beta_{k-1}-\beta_k}{\sqrt{\alpha_k}}\leq1\end{equation}

and

\begin{equation}\sum_{k=1}^\infty\frac{\alpha_k}{\beta_k}<267.\end{equation}

For $t \in \{m+1,...,T\}$ and $k \in \mathbb{Z}_+$, let
$$m_{k,t}=
\begin{cases}
\alpha_k\left(\frac{2\sigma K}{\Delta_{S_t}}\right)^2\cdot \ln(T) & \Delta_{S_t}>0, \\
+\infty & \Delta_{S_t}=0,
\end{cases}$$

and 
$$ A_{k,t} = \{i \in S_t|T_{i,t-1}\leq m_{k,t}\}.$$

Then we define an event:
$$\mathcal{G}_{k,t}=\{|A_{k,t}|\geq\beta_kK\},$$

which means “in the $t-th$ round, at least $\beta_{k}K$ arms in $S_{t}$ had been observed at most $m_{k,t}$ times."

\begin{lemma}
In the $t-th$ round, at least $\beta_{k}K$ arms in $S_t$ had been observed at most $m_{k,t}$ times.
\end{lemma}

\textit{Proof.} Assume that $\mathcal{H}_t$ happens and that none of $\mathcal{G}_{1,t},\mathcal{G}_{2,t},...$ happens. Then $|A_{k,t}|<\beta_{k}K$ for all $k\in \mathbb{Z}_+$.

Let $A_{0,t} = S_t$ and $\bar{A}_{k,t}=S_t\setminus A_{k,t}$ for $k\in \mathbb{Z}_+\cup \{0\}$. It is easy to see $\bar{A}_{k-1,t}\subseteq\bar{A}_{k,t}$ for all $k\in \mathbb{Z}_+$. Note that $\lim_{k \to \infty}m_{k,t}=0$. Thus there exists $N\in \mathbb{Z}_+$ such that $\bar{A}_{k,t}=S_t$ for all $k\geq N$, and then we have $S_t=\bigcup_{k=1}^\infty\left(\bar{A}_{k,t}\setminus\bar{A}_{k-1,t}\right)$. Finally, note that for all $i\in \bar{A}_{k,t}$, we have $T_{i,t-1}>m_{k,t}$. Therefore
$$\begin{aligned}
\sum_{i\in S_t}\frac{1}{\sqrt{T_{i,t-1}}} & =\sum_{k=1}^\infty\sum_{i\in\bar{A}_{k,t}\setminus\bar{A}_{k-1,t}}\frac{1}{\sqrt{T_{i,t-1}}}\leq\sum_{k=1}^\infty\sum_{i\in\bar{A}_{k,t}\setminus\bar{A}_{k-1,t}}\frac{1}{\sqrt{m_{k,t}}} \\
 & =\sum_{k=1}^\infty\frac{\left|\bar{A}_{k,t}\setminus\bar{A}_{k-1,t}\right|}{\sqrt{m_{k,t}}}=\sum_{k=1}^\infty\frac{\left|A_{k-1,t}\setminus A_{k,t}\right|}{\sqrt{m_{k,t}}}=\sum_{k=1}^\infty\frac{\left|A_{k-1,t}\right|-\left|A_{k,t}\right|}{\sqrt{m_{k,t}}} \\
 & =\frac{|S_t|}{\sqrt{m_{1,t}}}+\sum_{k=1}^\infty|A_{k,t}|\left(\frac{1}{\sqrt{m_{k+1,t}}}-\frac{1}{\sqrt{m_{k,t}}}\right) \\
 & <\frac{K}{\sqrt{m_{1,t}}}+\sum_{k=1}^\infty\beta_kK\left(\frac{1}{\sqrt{m_{k+1,t}}}-\frac{1}{\sqrt{m_{k,t}}}\right) \\
 & =\sum_{k=1}^\infty\frac{(\beta_{k-1}-\beta_k)K}{\sqrt{m_{k,t}}}.
\end{aligned}$$

Note that we asuume $\mathcal{H}_t$ happens. Denote $\sigma = \mathop{\max}\limits_{i\in S_t}\sigma(i)$, then we have: 
$$\begin{aligned}
\Delta_{S_t} & \leq 2\Lambda_S=2\mathop{\max}\limits_{i\in S_t}\sigma(i)\sqrt{\frac{6\ln(t)}{T_{i,t-1}}}\\
&\leq 2\sigma \cdot \sqrt{6\ln(T)}\cdot \mathop{\max}\limits_{i\in S_t}\frac{1}{\sqrt{T_{i,t-1}}}\\
&\leq 2\sigma \cdot \sqrt{6\ln(T)}\cdot \sum_{i\in S_t}\frac{1}{\sqrt{T_{i,t-1}}}\\
&<2\sigma \cdot \sqrt{6\ln(T)}\cdot \sum_{k=1}^\infty\frac{(\beta_{k-1}-\beta_k)K}{\sqrt{m_{k,t}}}\\
&=\sqrt{6}\sum_{k=1}^\infty\frac{\beta_{k-1}-\beta_k}{\sqrt{\alpha_k}}\cdot \Delta_{S_t}\leq\Delta_{S_t},
\end{aligned}$$

We reach a contradiction here. The proof of lemma 5 is completed.
\hfill $\blacksquare$

By Lemma 5 we have
$$\sum_{t=m+1}^T\mathbb{I} \{\mathcal{H}_t\}\Delta_{S_t}\leq\sum_{k=1}^\infty\sum_{t=m+1}^T\mathbb{I}\{\mathcal{G}_{k,t},\Delta_{S_t}>0\}\Delta_{S_t}.$$

For $i\in [m], k\in \mathbb{Z}_+, t\in \{m+1,...,T\}$, define an event
$$\mathcal{G}_{i,k,t}=\mathcal{G}_{k,t}\wedge\{i\in S_t,T_{i,t-1}\leq m_{k,t}\}.$$

Then by the definitions of $\mathcal{G}_{k,t}$ and $\mathcal{G}_{i,k,t}$ we have
$$\mathbb{I}\{\mathcal{G}_{k,t},\Delta_{S_t}>0\}\leq\frac{1}{\beta_kK}\sum_{i\in E_\mathrm{B}}\mathbb{I}\{\mathcal{G}_{i,k,t},\Delta_{S_t}>0\}.$$

Therefore
$$\sum_{t=m+1}^T\mathbb{I}\{\mathcal{H}_t\}\Delta_{S_t}\leq\sum_{i\in E_\mathrm{B}}\sum_{k=1}^\infty\sum_{t=m+1}^T\mathbb{I}\{\mathcal{G}_{i,k,t},\Delta_{S_t}>0\}\frac{\Delta_{S_t}}{\beta_kK}.$$

For each arm $i\in E_B$, suppose $i$ is contained in $N_i$ bad super arms $S_{i,1}^\mathrm{B},S_{i,2}^\mathrm{B},\ldots,S_{i,N_i}^\mathrm{B}$. Let $\Delta_{i,l} = \Delta_{S_{i,l}^\mathrm{B}}(l\in[N_i])$. Without loss of generality, we assume $\Delta_{i,1}\geq\Delta_{i,2}\geq\ldots\geq\Delta_{i,N_i}$. Note that $\Delta_{i,N_i}=\Delta_{i,\min}$. For convenience, we also define $\Delta_{i,0}=+\infty,\mathrm{~i.e.,~}\alpha_k\left(\frac{2\sigma K}{\Delta_{i,0}}\right)^2=0$. Then we have
$$\begin{aligned}
 & \sum_{t=m+1}^T\mathbb{I}\{\mathcal{H}_t\}\Delta_{S_t} \\
 & \leq\sum_{i\in E_\mathrm{B}}\sum_{k=1}^\infty\sum_{t=m+1}^T\sum_{l=1}^{N_i}\mathbb{I}\{\mathcal{G}_{i,k,t},S_t=S_{i,l}^\mathrm{B}\}\frac{\Delta_{S_t}}{\beta_kK} \\
 & \leq\sum_{i\in E_\mathrm{B}}\sum_{k=1}^\infty\sum_{t=m+1}^T\sum_{l=1}^{N_i}\mathbb{I}\{T_{i,t-1}\leq m_{k,t},S_t=S_{i,l}^\mathrm{B}\}\frac{\Delta_{i,l}}{\beta_kK} \\
 & =\sum_{i\in E_\mathrm{B}}\sum_{k=1}^\infty\sum_{t=m+1}^T\sum_{l=1}^{N_i}\mathbb{I}\left\{T_{i,t-1}\leq\alpha_k\left(\frac{2\sigma K}{\Delta_{i,l}}\right)^2\ln T,S_t=S_{i,l}^\mathrm{B}\right\}\frac{\Delta_{i,l}}{\beta_kK} \\
 & =\sum_{i\in E_{\mathrm{B}}}\sum_{k=1}^{\infty}\sum_{t=m+1}^{T}\sum_{l=1}^{N_{i}}\sum_{j=1}^{l}\mathbb{I}\left\{\alpha_k\left(\frac{2\sigma K}{\Delta_{i,j-1}}\right)^{2}\ln T<T_{i,t-1}\leq\alpha_k\left(\frac{2\sigma K}{\Delta_{i,j}}\right)^{2}\ln T,S_{t}=S_{i,l}^{\mathrm{B}}\right\}\frac{\Delta_{i,l}}{\beta_{k}K} \\
 &\leq\sum_{i\in E_{\mathrm{B}}}\sum_{k=1}^{\infty}\sum_{t=m+1}^{T}\sum_{l=1}^{N_{i}}\sum_{j=1}^{l}\mathbb{I}\left\{\alpha_k\left(\frac{2\sigma K}{\Delta_{i,j-1}}\right)^{2}\ln T<T_{i,t-1}\leq\alpha_k\left(\frac{2\sigma K}{\Delta_{i,j}}\right)^{2}\ln T,S_{t}=S_{i,l}^{\mathrm{B}}\right\}\frac{\Delta_{i,j}}{\beta_{k}K}\\
 &\leq\sum_{i\in E_{\mathrm{B}}}\sum_{k=1}^{\infty}\sum_{t=m+1}^{T}\sum_{l=1}^{N_{i}}\sum_{j=1}^{N_{i}}\mathbb{I}\left\{\alpha_k\left(\frac{2\sigma K}{\Delta_{i,j-1}}\right)^{2}\ln T<T_{i,t-1}\leq\alpha_k\left(\frac{2\sigma K}{\Delta_{i,j}}\right)^{2}\ln T,S_{t}=S_{i,l}^{\mathrm{B}}\right\}\frac{\Delta_{i,j}}{\beta_{k}K}\\
 & \leq\sum_{i\in E_\mathrm{B}}\sum_{k=1}^\infty\sum_{t=m+1}^T\sum_{j=1}^{N_i}\mathbb{I}\left\{\alpha_k\left(\frac{2\sigma K}{\Delta_{i,j-1}}\right)^2\ln T<T_{i,t-1}\leq\alpha_k\left(\frac{2\sigma K}{\Delta_{i,j}}\right)^2\ln T\right\}\frac{\Delta_{i,j}}{\beta_kK}\\
 \end{aligned}$$
$$
 \hspace{-11em}
 \begin{aligned}
 & \leq\sum_{i\in E_{\mathrm{B}}}\sum_{k=1}^{\infty}\sum_{j=1}^{N_{i}}\left(\alpha_{k}\left(\frac{2\sigma K}{\Delta_{i,j}}\right)^{2}\ln T-\alpha_{k}\left(\frac{2\sigma K}{\Delta_{i,j-1}}\right)^{2}\ln T\right)\frac{\Delta_{i,j}}{\beta_{k}K} \\
 & =4\sigma^2K\left(\sum_{k=1}^\infty\frac{\alpha_k}{\beta_k}\right)\ln T\cdot\sum_{i\in E_{\mathrm{B}}}\sum_{j=1}^{N_i}\left(\frac{1}{\Delta_{i,j}^2}-\frac{1}{\Delta_{i,j-1}^2}\right)\Delta_{i,j} \\
 & \leq1068\sigma^2K\ln T\cdot\sum_{i\in E_{\mathrm{B}}}\sum_{j=1}^{N_i}\left(\frac{1}{\Delta_{i,j}^2}-\frac{1}{\Delta_{i,j-1}^2}\right)\Delta_{i,j},
\end{aligned}
$$
where the last inequality is due to (18).

Finally, for each $i\in E_B$ we have 
$$\begin{aligned}
\sum_{j=1}^{N_i}\left(\frac{1}{\Delta_{i,j}^2}-\frac{1}{\Delta_{i,j-1}^2}\right)\Delta_{i,j} & =\frac{1}{\Delta_{i,N_i}}+\sum_{j=1}^{N_i-1}\frac{1}{\Delta_{i,j}^2}(\Delta_{i,j}-\Delta_{i,j+1}) \\
 & \leq\frac{1}{\Delta_{i,N_i}}+\int_{\Delta_{i,N_i}}^{\Delta_{i,1}}\frac{1}{x^2}\mathrm{d}x \\
 & =\frac{2}{\Delta_{i,N_i}}-\frac{1}{\Delta_{i,1}} \\
 & <\frac{2}{\Delta_{i,\min}}.
\end{aligned}$$

It follows that 
\begin{equation}
	\begin{aligned}
	\sum_{t=m+1}^T\mathbb{I}\{\mathcal{H}_t\}\Delta_{S_t}&\leq1068\sigma^2K\ln T\cdot\sum_{i\in E_\mathrm{B}}\frac{2}{\Delta_{i,\min}}\\
	&=\sigma^2K\sum_{i\in E_\mathrm{B}}\frac{2136}{\Delta_{i,\min}}\ln T.
	\end{aligned}
\end{equation}
Combining (19) with Lemma 4, the distribution-dependent regret bound in Theorem 1 is proved.

To prove the distribution-independent bound, we decompose $\sum_{t=m+1}^T\mathbb{I}\{\mathcal{H}_t\}\Delta_{S_t}$ into two parts:
\begin{equation}\begin{aligned}
\sum_{t=m+1}^T\mathbb{I}\{\mathcal{H}_t\}\Delta_{S_t}&=\sum_{t=m+1}^T\mathbb{I}\{\mathcal{H}_t,\Delta_{S_t}\leq\epsilon\}\Delta_{S_t}\\
&+\sum_{t=m+1}^T\mathbb{I}\{\mathcal{H}_t,\Delta_{S_t}>\epsilon\}\Delta_{S_t}\\
&\leq\epsilon T+\sum_{t=m+1}^T1\{\mathcal{H}_t,\Delta_{S_t}>\epsilon\}\Delta_{S_t},
\end{aligned}\end{equation}

where $\epsilon>0$ is a constant to be determined. The second term can be bounded in the same way as in the proof of the distribution-dependent regret bound, except that we only consider the case $\Delta_{S_t}>\epsilon$. Thus we can replace (19) by
\begin{equation}
	\begin{aligned}
		&\sum_{t=m+1}^T\mathbb{I}\{\mathcal{H}_t,\Delta_{S_t}>\epsilon\}\Delta_{S_t}\\
		&\leq \sigma^2K\sum_{i\in E_\mathrm{B},\Delta_{i,\min}>\epsilon}\frac{2136}{\Delta_{i,\min}}\ln T\\
		&\leq \sigma^2Km\frac{2136}{\epsilon}\ln T.
	\end{aligned}
\end{equation}

It follows that
$$\sum_{t=m+1}^T\mathbb{I}\{\mathcal{H}_t\}\Delta_{S_t}\leq\epsilon T+\sigma^2Km\frac{2136}{\epsilon}\ln T.$$

Finally, letting $\epsilon=\sqrt{\frac{2136\sigma^2Km\ln T}{T}}$, we get 
$$\sum_{t=m+1}^T\mathbb{I}\{\mathcal{H}_t\}\Delta_{S_t}\leq2\sqrt{2136\sigma^2KmT\ln T}<93\sigma\sqrt{mKT\ln T}.$$

Combining this with Lemma 4, we conclude the proof of the distribution-independent regret bound in Theorem 1.\hfill $\blacksquare$


\bibliographystyle{informs2014} 
\bibliography{sample} 

%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%



