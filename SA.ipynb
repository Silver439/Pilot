{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ddfd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from util.data_generate import *\n",
    "from util.methods import *\n",
    "\n",
    "# ---------------------------- 初始化参数 ----------------------------\n",
    "p = 50  # 科目总数\n",
    "m = 8   # 需要选择的科目数\n",
    "group_sizes = [10] * 5\n",
    "seed, J, n_iter, num_repeats = 1, 10000, 150, 30\n",
    "np.random.seed(seed)\n",
    "Sigma1 = np.loadtxt(\"Sigma1.txt\")\n",
    "mu1 = 70 * np.ones(p)\n",
    "mu2, std2, R2, Sigma2 = data2(p=p, seed=seed, group_sizes=group_sizes)\n",
    "mu = np.random.multivariate_normal(mu1, Sigma1)\n",
    "\n",
    "# ---------------------------- 模拟环境 ----------------------------\n",
    "class ExamEnvironment:\n",
    "    def __init__(self, n_subjects=50):\n",
    "        np.random.seed(42)\n",
    "        self.true_means = mu\n",
    "        self.cov_matrix = np.loadtxt(\"Sigma1.txt\")\n",
    "        \n",
    "    def observe_scores(self, selected_indices: List[int]) -> List[float]:\n",
    "        ids = selected_indices\n",
    "        return np.random.multivariate_normal(mu[ids], Sigma2[np.ix_(ids, ids)])\n",
    "\n",
    "# ---------------------------- 动态概率编码器 ----------------------------\n",
    "class DynamicProbabilityEncoder:\n",
    "    def __init__(self, n_subjects: int):\n",
    "        self.n_subjects = n_subjects\n",
    "        self.prob_vector = np.ones(n_subjects) / n_subjects\n",
    "    \n",
    "    def update(self, sample_means: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        使用 Softmax 更新科目被选入候选集的概率：\n",
    "        \"\"\"\n",
    "        # 1. 越小均值对应的值越大\n",
    "        inverted_means = 80-sample_means\n",
    "        \n",
    "        # 2. 计算 Softmax（确保数值稳定）\n",
    "        max_inverted = np.max(inverted_means)\n",
    "        exp_values = np.exp((inverted_means - max_inverted))\n",
    "        softmax_probs = exp_values / np.sum(exp_values)\n",
    "        \n",
    "        # 4. 归一化并更新概率\n",
    "        self.prob_vector = softmax_probs / np.sum(softmax_probs)\n",
    "        \n",
    "    def sample_candidates(self, size: int) -> List[int]:\n",
    "        return sorted(np.random.choice(\n",
    "            self.n_subjects, size=size, replace=False, p=self.prob_vector\n",
    "        ))\n",
    "\n",
    "# ---------------------------- 模拟退火算法 ----------------------------\n",
    "class MultiStartSA:\n",
    "    def __init__(self, select_size=8, n_starts=6, inner_iters=100):\n",
    "        self.select_size = select_size\n",
    "        self.n_starts = n_starts      # 并行启动的SA数量\n",
    "        self.inner_iters = inner_iters # 每个SA的内部迭代次数\n",
    "        self.T_init = 100.0           # 初始温度\n",
    "        self.cooling_rate = 0.95      # 冷却速率\n",
    "\n",
    "    def fitness(self, solution: List[int], sample_means: np.ndarray) -> float:\n",
    "        \"\"\"计算最小值期望\"\"\"\n",
    "        z_samples = np.random.randn(J, self.select_size)\n",
    "        sub_Sigma = Sigma2[np.ix_(solution, solution)]\n",
    "        U = np.linalg.cholesky(sub_Sigma)\n",
    "        return np.mean(np.min(sample_means[solution] + (U @ z_samples.T).T, axis=1))\n",
    "\n",
    "    def get_neighbor(self, current_solution: List[int], candidates: List[int]) -> List[int]:\n",
    "        \"\"\"邻域：随机替换一门科目\"\"\"\n",
    "        neighbor = current_solution.copy()\n",
    "        idx_to_replace = random.randint(0, self.select_size - 1)\n",
    "        available = list(set(candidates) - set(neighbor))\n",
    "        if available:\n",
    "            neighbor[idx_to_replace] = random.choice(available)\n",
    "        return sorted(neighbor)\n",
    "\n",
    "    def run_single_sa(self, initial_solution: List[int], candidates: List[int], sample_means: np.ndarray) -> List[int]:\n",
    "        \"\"\"单个SA的独立运行\"\"\"\n",
    "        current_solution = initial_solution.copy()\n",
    "        current_energy = self.fitness(current_solution, sample_means)\n",
    "        best_solution = current_solution.copy()\n",
    "        best_energy = current_energy\n",
    "        T = self.T_init\n",
    "\n",
    "        for _ in range(self.inner_iters):\n",
    "            neighbor = self.get_neighbor(current_solution, candidates)\n",
    "            neighbor_energy = self.fitness(neighbor, sample_means)\n",
    "            delta_E = neighbor_energy - current_energy\n",
    "\n",
    "            # 接受条件\n",
    "            if delta_E < 0 or random.random() < np.exp(-delta_E / T):\n",
    "                current_solution = neighbor\n",
    "                current_energy = neighbor_energy\n",
    "\n",
    "            # 更新全局最优\n",
    "            if current_energy < best_energy:\n",
    "                best_solution = current_solution.copy()\n",
    "                best_energy = current_energy\n",
    "\n",
    "            T *= self.cooling_rate\n",
    "\n",
    "        return best_solution\n",
    "\n",
    "    def optimize(self, candidates: List[int], sample_means: np.ndarray) -> List[int]:\n",
    "        \"\"\"多起点SA主流程（串行版）\"\"\"\n",
    "        # 生成多个初始解\n",
    "        initial_solutions = [random.sample(candidates, self.select_size) \n",
    "                           for _ in range(self.n_starts)]\n",
    "\n",
    "        # 运行多个SA\n",
    "        results = []\n",
    "        for sol in initial_solutions:\n",
    "            best_sol = self.run_single_sa(sol, candidates, sample_means)\n",
    "            results.append(best_sol)\n",
    "\n",
    "        # 选择所有结果中适应度最好的解\n",
    "        best_solution = min(results, key=lambda x: self.fitness(x, sample_means))\n",
    "        return best_solution\n",
    "\n",
    "# ---------------------------- 主优化流程 ----------------------------\n",
    "csv_path = f'{p}_{m}_SA.csv'\n",
    "csv_path1 = f'{p}_{m}_SA_pre.csv'\n",
    "csv_path2 = f'{p}_{m}_SA_post.csv'\n",
    "\n",
    "# 初始化CSV文件\n",
    "with open(csv_path, 'w') as f:\n",
    "    f.write(','.join(['Repetition'] + [f'Step_{i}' for i in range(1, n_iter + 1)]) + '\\n')\n",
    "with open(csv_path1, 'w') as f:\n",
    "    f.write(','.join(['Repetition'] + [f'Step_{i}' for i in range(1, n_iter + 1)]) + '\\n')\n",
    "with open(csv_path2, 'w') as f:\n",
    "    f.write(','.join(['Repetition'] + [f'Step_{i}' for i in range(1, n_iter + 1)]) + '\\n')\n",
    "\n",
    "# 初始化环境与组件\n",
    "env = ExamEnvironment(n_subjects=50)\n",
    "encoder = DynamicProbabilityEncoder(n_subjects=50)\n",
    "ms_sa = MultiStartSA(select_size=8, n_starts=5, inner_iters=100)\n",
    "\n",
    "for repeat in range(num_repeats):\n",
    "    obs_num = np.zeros(p)\n",
    "    history = {\n",
    "        'best_groups': [],\n",
    "        'prob_entropy': [],\n",
    "        'sample_means': np.full(50, 70.0)  # 初始样本均值\n",
    "    }\n",
    "    G, G_pre, G_post = [], [], []\n",
    "\n",
    "    for epoch in tqdm(range(n_iter)):\n",
    "        # 1. 动态生成候选集\n",
    "        candidates = encoder.sample_candidates(size=20)\n",
    "        \n",
    "        # 2. 运行模拟退火算法\n",
    "        best_individual = ms_sa.optimize(candidates, history['sample_means'])\n",
    "        \n",
    "        # 3. 观测分数并更新\n",
    "        observed_scores = env.observe_scores(best_individual)\n",
    "        obs_num[best_individual] += 1\n",
    "        for idx, score in zip(best_individual, observed_scores):\n",
    "            history['sample_means'][idx] = 0.8 * history['sample_means'][idx] + 0.2 * score\n",
    "        \n",
    "        # 4. 更新概率编码器\n",
    "        encoder.update(history['sample_means'])\n",
    "        \n",
    "        # 5. 记录\n",
    "        history['best_groups'].append(best_individual)\n",
    "        history['prob_entropy'].append(-np.sum(encoder.prob_vector * np.log(encoder.prob_vector + 1e-10)))\n",
    "\n",
    "        z_samples = np.random.randn(J * 10, m)\n",
    "        sub_Sigma = Sigma2[np.ix_(best_individual, best_individual)]\n",
    "        U = np.linalg.cholesky(sub_Sigma)\n",
    "        G.append(np.mean(np.min(mu[best_individual] + (U @ z_samples.T).T, axis=1)))\n",
    "\n",
    "        Gmin = 1000\n",
    "        idmin = []\n",
    "        z_samples2 = np.random.randn(J, m)\n",
    "        for id in history['best_groups']:\n",
    "            sub_Sigma = Sigma2[np.ix_(id, id)]\n",
    "            B = np.linalg.cholesky(sub_Sigma)\n",
    "            Gtemp = np.mean(np.min(history['sample_means'][id] + (B @ z_samples2.T).T, axis=1))\n",
    "            if Gtemp < Gmin:\n",
    "                idmin = id.copy()\n",
    "                Gmin = Gtemp\n",
    "        ids1 = idmin\n",
    "\n",
    "        sub_Sigma1 = Sigma2[np.ix_(ids1, ids1)]\n",
    "        U1 = np.linalg.cholesky(sub_Sigma1)\n",
    "        G_pre.append(np.mean(np.min(mu[ids1] + (U1 @ z_samples.T).T, axis=1)))\n",
    "\n",
    "        U2, ids2 = improvement(p, m, history['sample_means'], std2, R2, Sigma2, J=J)\n",
    "        G_post.append(np.mean(np.min(mu[ids2] + (U2 @ z_samples.T).T, axis=1)))\n",
    "    \n",
    "    # 保存结果\n",
    "    U3, ids3 = improvement(p, m, mu, std2, R2, Sigma2, J=J)\n",
    "    z_samples = np.random.randn(J * 10, m)\n",
    "    G_real = np.mean(np.min(mu[ids3] + (U3 @ z_samples.T).T, axis=1))\n",
    "\n",
    "    with open(csv_path, 'a') as f:\n",
    "        f.write(','.join([str(repeat)] + [f'{x:.6f}' for x in np.array(G) - G_real]) + '\\n')\n",
    "    with open(csv_path1, 'a') as f:\n",
    "        f.write(','.join([str(repeat)] + [f'{x:.6f}' for x in np.array(G_pre) - G_real]) + '\\n')\n",
    "    with open(csv_path2, 'a') as f:\n",
    "        f.write(','.join([str(repeat)] + [f'{x:.6f}' for x in np.array(G_post) - G_real]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b9e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03997641",
   "metadata": {},
   "outputs": [],
   "source": [
    "history['sample_means']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
