{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8051273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [05:39<00:00, 11.32s/it]\n",
      "100%|██████████| 30/30 [13:21<00:00, 26.70s/it]\n",
      "100%|██████████| 30/30 [27:35<00:00, 55.19s/it]\n"
     ]
    }
   ],
   "source": [
    "#TS\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import multivariate_normal\n",
    "from util.data_generate import *\n",
    "from util.methods import *\n",
    "import csv\n",
    "\n",
    "p = 50\n",
    "group_sizes = [10]*5\n",
    "seed, J, n_iter, num_repeats = 1, 10000, 150, 30\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "Sigma2 = np.loadtxt('Data_generate\\group_cov.txt')\n",
    "std2 = np.sqrt(np.diag(Sigma2))\n",
    "R2 = Sigma2 / np.outer(std2, std2)\n",
    "mu = np.loadtxt('Data_generate\\mu.txt')\n",
    "\n",
    "Sigma1 = np.loadtxt('Data_generate\\Sigma1.txt')\n",
    "Sigma1 = Sigma1 * 4\n",
    "\n",
    "for m in [5,8,12]:\n",
    "    csv_path = f'{p}_{m}_TS.csv'\n",
    "    csv_path1 = f'{p}_{m}_TS_pre.csv'\n",
    "    csv_path2 = f'{p}_{m}_TS_post.csv'\n",
    "\n",
    "    # Initialize CSV\n",
    "    with open(csv_path, 'w') as f:\n",
    "        f.write(','.join(['Repetition'] + [f'Step_{i}' for i in range(1, n_iter+1)]) + '\\n')\n",
    "    with open(csv_path1, 'w') as f:\n",
    "        f.write(','.join(['Repetition'] + [f'Step_{i}' for i in range(1, n_iter+1)]) + '\\n')\n",
    "    with open(csv_path2, 'w') as f:\n",
    "        f.write(','.join(['Repetition'] + [f'Step_{i}' for i in range(1, n_iter+1)]) + '\\n')\n",
    "\n",
    "    for repeat in tqdm(range(num_repeats)):\n",
    "        \n",
    "        # Initialize variables\n",
    "        mu_0 = np.full(p, 70)\n",
    "        mu_hat, var_hat, obs_num = np.zeros(p), np.ones(p), np.zeros(p)\n",
    "        \n",
    "        # First observation\n",
    "        _, ids = improvement(p, m, mu_0, std2, R2, Sigma2, J=J)\n",
    "        obs_num[ids] += 1\n",
    "        indices = ids.copy()\n",
    "        obs = np.random.multivariate_normal(mu[ids], Sigma2[np.ix_(ids, ids)])\n",
    "        X_n = ids.copy()\n",
    "        \n",
    "        # Update estimates\n",
    "        Gamma = Sigma2[np.ix_(ids, ids)]\n",
    "        inv_mat = np.linalg.inv(Sigma1[np.ix_(ids, ids)] + Gamma)\n",
    "        delta = (obs - mu_0[ids]).reshape(-1, 1)\n",
    "        \n",
    "        COV_x = Sigma1[:, ids]\n",
    "        adjustments = (COV_x @ inv_mat @ delta).flatten()\n",
    "        mu_hat = mu_0 + adjustments\n",
    "\n",
    "        Sigma_XX = np.eye(p)\n",
    "        COV_Xn = Sigma1[:, X_n]\n",
    "        temp = COV_Xn @ inv_mat @ COV_Xn.T\n",
    "        Sigma_XX = Sigma1 - temp\n",
    "\n",
    "        Sigma_XX = np.triu(Sigma_XX)  # Take upper triangle\n",
    "        Sigma_XX += Sigma_XX.T  # Make symmetric\n",
    "        np.fill_diagonal(Sigma_XX, np.diag(Sigma_XX)/2)  # Correct diagonal\n",
    "\n",
    "        # Main loop\n",
    "        G = [] #用于计算累积遗憾\n",
    "        G_pre = [] \n",
    "        G_post = []\n",
    "        for _ in range(1, n_iter+1):\n",
    "\n",
    "            mu_TS = np.random.multivariate_normal(mu_hat, Sigma_XX)\n",
    "            U, ids = improvement(p, m, mu_TS, std2, R2, Sigma2, J=J)\n",
    "            obs_num[ids] += 1\n",
    "            indices = np.vstack((indices, ids))\n",
    "            \n",
    "            newobs = np.random.multivariate_normal(mu[ids], Sigma2[np.ix_(ids, ids)])\n",
    "            X_n, obs = update_subject_stats(obs_num, X_n, obs, ids, newobs)\n",
    "            \n",
    "            # Update Gamma matrix\n",
    "            len_Xn = len(X_n)\n",
    "            Gamma = np.zeros((len_Xn, len_Xn))\n",
    "            for i in range(len_Xn):\n",
    "                for j in range(i, len_Xn):\n",
    "                    count = np.sum((indices == X_n[i]).any(1) & (indices == X_n[j]).any(1))\n",
    "                    Gamma[i,j] = Sigma2[X_n[i],X_n[j]] * count / (obs_num[X_n[i]] * obs_num[X_n[j]])\n",
    "            Gamma += Gamma.T\n",
    "            np.fill_diagonal(Gamma, np.diag(Gamma)/2)\n",
    "            \n",
    "            # Update estimates\n",
    "            COV_XX = Sigma1[np.ix_(X_n, X_n)]\n",
    "            inv_mat = np.linalg.inv(COV_XX + Gamma)\n",
    "            delta = (obs - mu_0[X_n]).reshape(-1, 1)\n",
    "            \n",
    "            COV_x = Sigma1[:, X_n]\n",
    "            adjustments = (COV_x @ inv_mat @ delta).flatten()\n",
    "            mu_hat = mu_0 + adjustments\n",
    "\n",
    "            Sigma_XX = np.eye(p)\n",
    "            COV_Xn = Sigma1[:, X_n]\n",
    "            temp = COV_Xn @ inv_mat @ COV_Xn.T\n",
    "            Sigma_XX = Sigma1 - temp\n",
    "\n",
    "            Sigma_XX = np.triu(Sigma_XX)  # Take upper triangle\n",
    "            Sigma_XX += Sigma_XX.T  # Make symmetric\n",
    "            np.fill_diagonal(Sigma_XX, np.diag(Sigma_XX)/2)  # Correct diagonal\n",
    "\n",
    "            # Calculate G\n",
    "            z_samples = np.random.randn(J*10, m)\n",
    "            G.append(np.mean(np.min(mu[ids] + (U @ z_samples.T).T, axis=1)))\n",
    "\n",
    "            Gmin = 1000\n",
    "            idmin = []\n",
    "            z_samples2 = np.random.randn(J, m)\n",
    "            for id in indices:\n",
    "                sub_Sigma = Sigma2[np.ix_(id, id)]\n",
    "                B = np.linalg.cholesky(sub_Sigma)\n",
    "                Gtemp = np.mean(np.min(mu_hat[id] + (B @ z_samples2.T).T, axis=1))\n",
    "                if Gtemp < Gmin:\n",
    "                    idmin = id.copy()\n",
    "                    Gmin = Gtemp\n",
    "            ids1 = idmin\n",
    "\n",
    "            sub_Sigma = Sigma2[np.ix_(ids1, ids1)]\n",
    "            U1 = np.linalg.cholesky(sub_Sigma)\n",
    "            G_pre.append(np.mean(np.min(mu[ids1] + (U1 @ z_samples.T).T, axis=1)))\n",
    "            \n",
    "            # Calculate G_post\n",
    "            U2, ids2 = improvement(p, m, mu_hat, std2, R2, Sigma2, J=J)\n",
    "            #z_samples = np.random.randn(J*10, m)\n",
    "            G_post.append(np.mean(np.min(mu[ids2] + (U2 @ z_samples.T).T, axis=1)))\n",
    "        \n",
    "        # Calculate G_real\n",
    "        U3, ids3 = improvement(p, m, mu, std2, R2, Sigma2, J=J)\n",
    "        z_samples = np.random.randn(J*10, m)\n",
    "        G_real = np.mean(np.min(mu[ids3] + (U3 @ z_samples.T).T, axis=1))\n",
    "        \n",
    "        # Save results\n",
    "        with open(csv_path, 'a') as f:\n",
    "            f.write(','.join([str(repeat)] + [f'{x:.6f}' for x in np.array(G)-G_real]) + '\\n')\n",
    "        with open(csv_path1, 'a') as f:\n",
    "            f.write(','.join([str(repeat)] + [f'{x:.6f}' for x in np.array(G_pre)-G_real]) + '\\n')\n",
    "        with open(csv_path2, 'a') as f:\n",
    "            f.write(','.join([str(repeat)] + [f'{x:.6f}' for x in np.array(G_post)-G_real]) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47f3055c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:42<00:00,  7.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 50_5_Uni.csv and 50_5_Uni_post.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [08:03<00:00, 16.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 50_8_Uni.csv and 50_8_Uni_post.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [15:53<00:00, 31.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 50_12_Uni.csv and 50_12_Uni_post.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Uniform\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import multivariate_normal\n",
    "from util.data_generate import *\n",
    "from util.methods import *\n",
    "import csv\n",
    "\n",
    "p= 50\n",
    "group_sizes = [10]*5\n",
    "seed, J, n_iter, num_repeats = 1, 10000, 150, 30\n",
    "np.random.seed(seed=seed)\n",
    "#Sigma1 = generate_cov_matrix(p)\n",
    "Sigma1 = np.loadtxt(\"Sigma1.txt\")\n",
    "Sigma1 = Sigma1 * 4\n",
    "Sigma2 = np.loadtxt('group_cov.txt')\n",
    "std2 = np.sqrt(np.diag(Sigma2))\n",
    "R2 = Sigma2 / np.outer(std2, std2)\n",
    "mu = np.loadtxt('mu.txt')\n",
    "for m in [5,8,12]:\n",
    "    csv_path = f'{p}_{m}_Uni.csv'\n",
    "    csv_path1 = f'{p}_{m}_Uni_pre.csv'\n",
    "    csv_path2 = f'{p}_{m}_Uni_post.csv'\n",
    "\n",
    "    # Initialize CSV\n",
    "    with open(csv_path, 'w') as f:\n",
    "        f.write(','.join(['Repetition'] + [f'Step_{i}' for i in range(1, n_iter+1)]) + '\\n')\n",
    "    with open(csv_path1, 'w') as f:\n",
    "        f.write(','.join(['Repetition'] + [f'Step_{i}' for i in range(1, n_iter+1)]) + '\\n')\n",
    "    with open(csv_path2, 'w') as f:\n",
    "        f.write(','.join(['Repetition'] + [f'Step_{i}' for i in range(1, n_iter+1)]) + '\\n')\n",
    "\n",
    "    for repeat in tqdm(range(num_repeats)):\n",
    "        seed = seed + repeat\n",
    "        # Initialize variables\n",
    "        mu_0 = np.full(p, 70)\n",
    "        mu_hat, var_hat, obs_num = np.zeros(p), np.ones(p), np.zeros(p)\n",
    "        \n",
    "        # First observation\n",
    "        _, ids = improvement(p, m, mu_0, std2, R2, Sigma2, J=J)\n",
    "        obs_num[ids] += 1\n",
    "        indices = ids.copy()\n",
    "        obs = np.random.multivariate_normal(mu[ids], Sigma2[np.ix_(ids, ids)])\n",
    "        X_n = ids.copy()\n",
    "        \n",
    "        # Update estimates\n",
    "        Gamma = Sigma2[np.ix_(ids, ids)]\n",
    "        inv_mat = np.linalg.inv(Sigma1[np.ix_(ids, ids)] + Gamma)\n",
    "        delta = (obs - mu_0[ids]).reshape(-1, 1)\n",
    "        \n",
    "        COV_x = Sigma1[:, ids]\n",
    "        adjustments = (COV_x @ inv_mat @ delta).flatten()\n",
    "        mu_hat = mu_0 + adjustments\n",
    "\n",
    "        # Main loop\n",
    "        G = [] #用于计算累积遗憾\n",
    "        G_pre = [] \n",
    "        G_post = []\n",
    "        for _ in range(1, n_iter+1):\n",
    "            ids = np.argsort(obs_num)[:m]\n",
    "            sub_Sigma0 = Sigma2[np.ix_(ids, ids)]\n",
    "            U = np.linalg.cholesky(sub_Sigma0)\n",
    "            obs_num[ids] += 1\n",
    "            indices = np.vstack((indices, ids))\n",
    "            \n",
    "            newobs = np.random.multivariate_normal(mu[ids], Sigma2[np.ix_(ids, ids)])\n",
    "            X_n, obs = update_subject_stats(obs_num, X_n, obs, ids, newobs)\n",
    "            \n",
    "            # Update Gamma matrix\n",
    "            len_Xn = len(X_n)\n",
    "            Gamma = np.zeros((len_Xn, len_Xn))\n",
    "            for i in range(len_Xn):\n",
    "                for j in range(i, len_Xn):\n",
    "                    count = np.sum((indices == X_n[i]).any(1) & (indices == X_n[j]).any(1))\n",
    "                    Gamma[i,j] = Sigma2[X_n[i],X_n[j]] * count / (obs_num[X_n[i]] * obs_num[X_n[j]])\n",
    "            Gamma += Gamma.T\n",
    "            np.fill_diagonal(Gamma, np.diag(Gamma)/2)\n",
    "            \n",
    "            # Update estimates\n",
    "            COV_XX = Sigma1[np.ix_(X_n, X_n)]\n",
    "            inv_mat = np.linalg.inv(COV_XX + Gamma)\n",
    "            delta = (obs - mu_0[X_n]).reshape(-1, 1)\n",
    "            \n",
    "            COV_x = Sigma1[:, X_n]\n",
    "            adjustments = (COV_x @ inv_mat @ delta).flatten()\n",
    "            mu_hat = mu_0 + adjustments\n",
    "            \n",
    "            # Calculate G\n",
    "            z_samples = np.random.randn(J*10, m)\n",
    "            G.append(np.mean(np.min(mu[ids] + (U @ z_samples.T).T, axis=1)))\n",
    "\n",
    "            Gmin = 1000\n",
    "            idmin = []\n",
    "            z_samples2 = np.random.randn(J, m)\n",
    "            for id in indices:\n",
    "                sub_Sigma = Sigma2[np.ix_(id, id)]\n",
    "                B = np.linalg.cholesky(sub_Sigma)\n",
    "                Gtemp = np.mean(np.min(mu_hat[id] + (B @ z_samples2.T).T, axis=1))\n",
    "                if Gtemp < Gmin:\n",
    "                    idmin = id.copy()\n",
    "                    Gmin = Gtemp\n",
    "            ids1 = idmin\n",
    "\n",
    "            sub_Sigma = Sigma2[np.ix_(ids1, ids1)]\n",
    "            U1 = np.linalg.cholesky(sub_Sigma)\n",
    "            G_pre.append(np.mean(np.min(mu[ids1] + (U1 @ z_samples.T).T, axis=1)))\n",
    "            \n",
    "            # Calculate G_post\n",
    "            U2, ids2 = improvement(p, m, mu_hat, std2, R2, Sigma2, J=J)\n",
    "            #z_samples = np.random.randn(J*10, m)\n",
    "            G_post.append(np.mean(np.min(mu[ids2] + (U2 @ z_samples.T).T, axis=1)))\n",
    "        \n",
    "        # Calculate G_real\n",
    "        U3, ids3 = improvement(p, m, mu, std2, R2, Sigma2, J=J)\n",
    "        z_samples = np.random.randn(J*10, m)\n",
    "        G_real = np.mean(np.min(mu[ids3] + (U3 @ z_samples.T).T, axis=1))\n",
    "        \n",
    "        # Save results\n",
    "        with open(csv_path, 'a') as f:\n",
    "            f.write(','.join([str(repeat)] + [f'{x:.6f}' for x in np.array(G)-G_real]) + '\\n')\n",
    "        with open(csv_path1, 'a') as f:\n",
    "            f.write(','.join([str(repeat)] + [f'{x:.6f}' for x in np.array(G_pre)-G_real]) + '\\n')\n",
    "        with open(csv_path2, 'a') as f:\n",
    "            f.write(','.join([str(repeat)] + [f'{x:.6f}' for x in np.array(G_post)-G_real]) + '\\n')\n",
    "\n",
    "    print(f\"Results saved to {csv_path} and {csv_path2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2e44e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!shutdown -s -t 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd52d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
