{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2447fbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [06:53<00:00, 13.77s/it]\n",
      "100%|██████████| 30/30 [07:07<00:00, 14.26s/it]\n",
      "100%|██████████| 30/30 [12:49<00:00, 25.65s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import multivariate_normal\n",
    "from util.data_generate import *\n",
    "from util.methods import *\n",
    "import csv\n",
    "#random200\n",
    "p = 200\n",
    "betas = ['smallest','cluster','dynamic']\n",
    "seed, J, n_iter, num_repeats = 1, 10000, 150, 30\n",
    "np.random.seed(seed=seed)\n",
    "Sigma1 = np.loadtxt('Data_generate/Sigma1.txt')\n",
    "Sigma1 = Sigma1 * 4\n",
    "\n",
    "Sigma2 = np.loadtxt('Data_generate/group_cov.txt')\n",
    "std2 = np.sqrt(np.diag(Sigma2))\n",
    "R2 = Sigma2 / np.outer(std2, std2)\n",
    "mu = np.loadtxt('Data_generate/mu.txt')\n",
    "\n",
    "for m in [10,]:\n",
    "    U3, ids3 = SAA(p, m, mu, std2, R2, Sigma2, J=J)\n",
    "    z_samples = np.random.randn(J*10, m)\n",
    "    G_real = np.mean(np.min(mu[ids3] + (U3 @ z_samples.T).T, axis=1))\n",
    "    cluster_labels = cluster_subjects(R2, n_clusters=m, method='average')\n",
    "    for beta in betas:\n",
    "\n",
    "        csv_path = f'{p}_{m}_{beta}.csv'\n",
    "        csv_path1 = f'{p}_{m}_{beta}_pre.csv'\n",
    "        #csv_path2 = f'{p}_{m}_{beta}_post.csv'\n",
    "\n",
    "        # Initialize CSV\n",
    "        with open(csv_path, 'w') as f:\n",
    "            f.write(','.join(['Repetition'] + [f'Step_{i}' for i in range(1, n_iter+1)]) + '\\n')\n",
    "        with open(csv_path1, 'w') as f:\n",
    "            f.write(','.join(['Repetition'] + [f'Step_{i}' for i in range(1, n_iter+1)]) + '\\n')\n",
    "        # with open(csv_path2, 'w') as f:\n",
    "        #     f.write(','.join(['Repetition'] + [f'Step_{i}' for i in range(1, n_iter+1)]) + '\\n')\n",
    "\n",
    "        for repeat in tqdm(range(num_repeats)):\n",
    "            # Initial setup\n",
    "            seed = seed + repeat\n",
    "            \n",
    "            # Initialize variables\n",
    "            mu_0 = np.full(p, 70)\n",
    "            mu_hat, var_hat, obs_num = np.zeros(p), np.ones(p), np.zeros(p)\n",
    "            \n",
    "            # Initial observation\n",
    "            N_0 = math.ceil(p / m)\n",
    "            for i in range(N_0):\n",
    "                ids = efficient_initialization(p, m, obs_num, mu_0, std2, R2, Sigma2, J)\n",
    "                obs_num[ids] += 1\n",
    "                indices = ids.copy()\n",
    "                obs = np.random.multivariate_normal(mu[ids], Sigma2[np.ix_(ids, ids)])\n",
    "                X_n = ids.copy()\n",
    "                \n",
    "                # Update estimates\n",
    "                Gamma = Sigma2[np.ix_(ids, ids)]\n",
    "                inv_mat = np.linalg.inv(Sigma1[np.ix_(ids, ids)] + Gamma)\n",
    "                delta = (obs - mu_0[ids]).reshape(-1, 1)\n",
    "                \n",
    "                COV_x = Sigma1[:, ids]\n",
    "                adjustments = (COV_x @ inv_mat @ delta).flatten()\n",
    "                mu_hat = mu_0 + adjustments\n",
    "                adjustments = np.diag(COV_x @ inv_mat @ COV_x.T)\n",
    "                var_hat = np.diag(Sigma1) - adjustments\n",
    "                \n",
    "            # Main loop\n",
    "            G = [] #用于计算累积遗憾\n",
    "            G_pre = [] \n",
    "            #G_post = []\n",
    "            for t in range(N_0+1, n_iter+1):\n",
    "                if beta == 'dynamic':\n",
    "                    dynamic_beta = np.sqrt(6 * np.log(t) / np.maximum(obs_num, 1))\n",
    "                    U, ids = improvement(p, m, mu_hat - dynamic_beta * np.sqrt(var_hat), std2, R2, Sigma2, J=J)\n",
    "                elif beta == 'cluster': \n",
    "                    ids = find_min_mu_in_clusters(mu_hat, cluster_labels)\n",
    "                    sub_Sigma_cluster = Sigma2[np.ix_(ids, ids)]\n",
    "                    U = np.linalg.cholesky(sub_Sigma_cluster) \n",
    "                else:\n",
    "                    ids = np.argsort(mu_hat)[:m]\n",
    "                    sub_Sigma_smallest = Sigma2[np.ix_(ids, ids)]\n",
    "                    U = np.linalg.cholesky(sub_Sigma_smallest) \n",
    "                obs_num[ids] += 1\n",
    "                indices = np.vstack((indices, ids))\n",
    "                \n",
    "                newobs = np.random.multivariate_normal(mu[ids], Sigma2[np.ix_(ids, ids)])\n",
    "                X_n, obs = update_subject_stats(obs_num, X_n, obs, ids, newobs)\n",
    "                \n",
    "                # Update Gamma matrix\n",
    "                len_Xn = len(X_n)\n",
    "                Gamma = np.zeros((len_Xn, len_Xn))\n",
    "                for i in range(len_Xn):\n",
    "                    for j in range(i, len_Xn):\n",
    "                        count = np.sum((indices == X_n[i]).any(1) & (indices == X_n[j]).any(1))\n",
    "                        Gamma[i,j] = Sigma2[X_n[i],X_n[j]] * count / (obs_num[X_n[i]] * obs_num[X_n[j]])\n",
    "                Gamma += Gamma.T\n",
    "                np.fill_diagonal(Gamma, np.diag(Gamma)/2)\n",
    "                \n",
    "                # Update estimates\n",
    "                COV_XX = Sigma1[np.ix_(X_n, X_n)]\n",
    "                inv_mat = np.linalg.inv(COV_XX + Gamma)\n",
    "                delta = (obs - mu_0[X_n]).reshape(-1, 1)\n",
    "                \n",
    "                COV_x = Sigma1[:, X_n]\n",
    "                adjustments = (COV_x @ inv_mat @ delta).flatten()\n",
    "                mu_hat = mu_0 + adjustments\n",
    "                adjustments = np.diag(COV_x @ inv_mat @ COV_x.T)\n",
    "                var_hat = np.diag(Sigma1) - adjustments\n",
    "\n",
    "                # Calculate G\n",
    "                z_samples = np.random.randn(J*10, m)\n",
    "                G.append(np.mean(np.min(mu[ids] + (U @ z_samples.T).T, axis=1)))\n",
    "\n",
    "                Gmin = 1000\n",
    "                idmin = []\n",
    "                z_samples2 = np.random.randn(J, m)\n",
    "                for id in indices:\n",
    "                    sub_Sigma = Sigma2[np.ix_(id, id)]\n",
    "                    B = np.linalg.cholesky(sub_Sigma)\n",
    "                    Gtemp = np.mean(np.min(mu_hat[id] + (B @ z_samples2.T).T, axis=1))\n",
    "                    if Gtemp < Gmin:\n",
    "                        idmin = id.copy()\n",
    "                        Gmin = Gtemp\n",
    "                ids1 = idmin\n",
    "\n",
    "                sub_Sigma = Sigma2[np.ix_(ids1, ids1)]\n",
    "                U1 = np.linalg.cholesky(sub_Sigma)\n",
    "                G_pre.append(np.mean(np.min(mu[ids1] + (U1 @ z_samples.T).T, axis=1)))\n",
    "                \n",
    "                # Calculate G_post\n",
    "                #U2, ids2 = improvement(p, m, mu_hat, std2, R2, Sigma2, J=J)\n",
    "                #z_samples = np.random.randn(J*10, m)\n",
    "                #G_post.append(np.mean(np.min(mu[ids2] + (U2 @ z_samples.T).T, axis=1)))\n",
    "            \n",
    "            # Save results\n",
    "            with open(csv_path, 'a') as f:\n",
    "                f.write(','.join([str(repeat)] + [f'{x:.6f}' for x in np.array(G)-G_real]) + '\\n')\n",
    "            with open(csv_path1, 'a') as f:\n",
    "                f.write(','.join([str(repeat)] + [f'{x:.6f}' for x in np.array(G_pre)-G_real]) + '\\n')\n",
    "            # with open(csv_path2, 'a') as f:\n",
    "            #     f.write(','.join([str(repeat)] + [f'{x:.6f}' for x in np.array(G_post)-G_real]) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed74b1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25, 26, 24, 27, 23, 28, 22, 29])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
