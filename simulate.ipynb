{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c0c858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125, 91, 87, 141, 13, 104, 9, 7, 10, 8]: 46.8348546986495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [08:17<00:00, 16.59s/it]\n",
      "100%|██████████| 30/30 [09:15<00:00, 18.50s/it]\n",
      "100%|██████████| 30/30 [41:25<00:00, 82.86s/it]\n",
      "100%|██████████| 30/30 [1:53:37<00:00, 227.24s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import multivariate_normal\n",
    "from util.data_generate import *\n",
    "from util.methods import *\n",
    "import csv\n",
    "import random\n",
    "from util.calculate import MultivariateNormalMinimum\n",
    "#best\n",
    "p = 200\n",
    "#betas = ['smallest','cluster','dynamic','cyclic','independent']\n",
    "#betas = ['smallest','cluster','dynamic','cyclic']\n",
    "betas = ['independent']\n",
    "seed, J, n_iter, num_repeats = 1, 10000, 150, 30\n",
    "np.random.seed(seed=seed)\n",
    "Sigma1 = np.loadtxt('Data_generate/Sigma1.txt')\n",
    "Sigma1 = Sigma1 * 4\n",
    "\n",
    "Sigma2 = np.loadtxt('Data_generate/group_cov.txt')\n",
    "std2 = np.sqrt(np.diag(Sigma2))\n",
    "R2 = Sigma2 / np.outer(std2, std2)\n",
    "mu = np.loadtxt('Data_generate/mu.txt')\n",
    "\n",
    "Sigma0 = np.diag(np.diag(Sigma2))\n",
    "\n",
    "for m in [10,]:\n",
    "    U3, ids3 = cyclic_multstart(p, m, mu, std2, R2, Sigma2, J=J, mult=50)\n",
    "    z_samples = np.random.randn(J*100, m)\n",
    "    G_real = np.mean(np.min(mu[ids3] + (U3 @ z_samples.T).T, axis=1))\n",
    "    print(ids3,end=\": \")\n",
    "    print(G_real)\n",
    "#--------------------------------------------------------------------\n",
    "    G_real = 46.8348546986495\n",
    "#--------------------------------------------------------------------\n",
    "    cluster_labels = cluster_subjects(R2, n_clusters=m, method='average')\n",
    "    for beta in betas:\n",
    "\n",
    "        detail_csv_path = f'{p}_{m}_{beta}_details.csv'\n",
    "        detail_records = []  # 用于批量存储\n",
    "\n",
    "        csv_path = f'{p}_{m}_{beta}.csv'\n",
    "        csv_path1 = f'{p}_{m}_{beta}_pre.csv'\n",
    "\n",
    "        # Initialize CSV\n",
    "        with open(csv_path, 'w') as f:\n",
    "            f.write(','.join(['Repetition'] + [f'Step_{i}' for i in range(1, n_iter+1)]) + '\\n')\n",
    "        with open(csv_path1, 'w') as f:\n",
    "            f.write(','.join(['Repetition'] + [f'Step_{i}' for i in range(1, n_iter+1)]) + '\\n')\n",
    "\n",
    "        for repeat in tqdm(range(num_repeats)):\n",
    "            # Initial setup\n",
    "            seed = seed + repeat\n",
    "            \n",
    "            # Initialize variables\n",
    "            mu_0 = np.full(p, 70)\n",
    "            mu_hat, var_hat, obs_num = np.zeros(p), np.ones(p), np.zeros(p)\n",
    "            \n",
    "            # Initial observation\n",
    "            N_0 = math.ceil(p / m)\n",
    "            for i in range(N_0):\n",
    "                ids = efficient_initialization(p, m, obs_num, mu_0, std2, R2, Sigma2, J)\n",
    "                obs_num[ids] += 1\n",
    "                indices = ids.copy()\n",
    "                obs = np.random.multivariate_normal(mu[ids], Sigma2[np.ix_(ids, ids)])\n",
    "                X_n = ids.copy()\n",
    "                \n",
    "                # Update estimates\n",
    "                Gamma = Sigma2[np.ix_(ids, ids)]\n",
    "                inv_mat = np.linalg.inv(Sigma1[np.ix_(ids, ids)] + Gamma)\n",
    "                delta = (obs - mu_0[ids]).reshape(-1, 1)\n",
    "                \n",
    "                COV_x = Sigma1[:, ids]\n",
    "                adjustments = (COV_x @ inv_mat @ delta).flatten()\n",
    "                mu_hat = mu_0 + adjustments\n",
    "                adjustments = np.diag(COV_x @ inv_mat @ COV_x.T)\n",
    "                var_hat = np.diag(Sigma1) - adjustments\n",
    "                \n",
    "            # Main loop\n",
    "            G = [] #用于计算累积遗憾\n",
    "            G_pre = [] \n",
    "            for t in range(N_0+1, n_iter+1):\n",
    "                dynamic_beta = np.sqrt(6 * np.log(t) / np.maximum(obs_num, 1))\n",
    "                if beta == 'dynamic':\n",
    "                    U, ids = improvement(p, m, mu_hat - dynamic_beta * np.sqrt(var_hat), std2, R2, Sigma2, J=J)\n",
    "                elif beta == 'cluster': \n",
    "                    ids = find_min_mu_in_clusters(mu_hat - dynamic_beta * np.sqrt(var_hat), cluster_labels)\n",
    "                    sub_Sigma_cluster = Sigma2[np.ix_(ids, ids)]\n",
    "                    U = np.linalg.cholesky(sub_Sigma_cluster) \n",
    "                elif beta == 'cyclic': \n",
    "                    U, ids = cyclic_multstart(p,m,mu_hat - dynamic_beta * np.sqrt(var_hat),std2, R2,Sigma2,J=100000,mult=10)\n",
    "                elif beta == 'independent': \n",
    "                    ids = cyclic_multstart(p,m,mu_hat - dynamic_beta * np.sqrt(var_hat),std2, R2,Sigma0,J=100000,mult=10)[1]\n",
    "                    sub_Sigma_indep = Sigma2[np.ix_(ids, ids)]\n",
    "                    U = np.linalg.cholesky(sub_Sigma_indep)\n",
    "                else:\n",
    "                    ids = np.argsort(mu_hat - dynamic_beta * np.sqrt(var_hat))[:m]\n",
    "                    sub_Sigma_smallest = Sigma2[np.ix_(ids, ids)]\n",
    "                    U = np.linalg.cholesky(sub_Sigma_smallest) \n",
    "                obs_num[ids] += 1\n",
    "                indices = np.vstack((indices, ids))\n",
    "                \n",
    "                newobs = np.random.multivariate_normal(mu[ids], Sigma2[np.ix_(ids, ids)])\n",
    "                X_n, obs = update_subject_stats(obs_num, X_n, obs, ids, newobs)\n",
    "                \n",
    "                # Update Gamma matrix\n",
    "                len_Xn = len(X_n)\n",
    "                Gamma = np.zeros((len_Xn, len_Xn))\n",
    "                for i in range(len_Xn):\n",
    "                    for j in range(i, len_Xn):\n",
    "                        count = np.sum((indices == X_n[i]).any(1) & (indices == X_n[j]).any(1))\n",
    "                        Gamma[i,j] = Sigma2[X_n[i],X_n[j]] * count / (obs_num[X_n[i]] * obs_num[X_n[j]])\n",
    "                Gamma += Gamma.T\n",
    "                np.fill_diagonal(Gamma, np.diag(Gamma)/2)\n",
    "                \n",
    "                # Update estimates\n",
    "                COV_XX = Sigma1[np.ix_(X_n, X_n)]\n",
    "                inv_mat = np.linalg.inv(COV_XX + Gamma)\n",
    "                delta = (obs - mu_0[X_n]).reshape(-1, 1)\n",
    "                \n",
    "                COV_x = Sigma1[:, X_n]\n",
    "                adjustments = (COV_x @ inv_mat @ delta).flatten()\n",
    "                mu_hat = mu_0 + adjustments\n",
    "                adjustments = np.diag(COV_x @ inv_mat @ COV_x.T)\n",
    "                var_hat = np.diag(Sigma1) - adjustments\n",
    "\n",
    "                # Calculate G\n",
    "                z_samples = np.random.randn(J*10, m)\n",
    "                observe_value = np.mean(np.min(mu[ids] + (U @ z_samples.T).T, axis=1))\n",
    "                G.append(observe_value)\n",
    "\n",
    "                modules_str = '_'.join(map(str, ids))\n",
    "                detail_records.append([beta, repeat+1, t, modules_str, f'{observe_value:.6f}'])\n",
    "\n",
    "                Gmin = 1000\n",
    "                idmin = []\n",
    "                z_samples2 = np.random.randn(J, m)\n",
    "                for id in indices:\n",
    "                    sub_Sigma = Sigma2[np.ix_(id, id)]\n",
    "                    B = np.linalg.cholesky(sub_Sigma)\n",
    "                    Gtemp = np.mean(np.min(mu_hat[id] + (B @ z_samples2.T).T, axis=1))\n",
    "                    if Gtemp < Gmin:\n",
    "                        idmin = id.copy()\n",
    "                        Gmin = Gtemp\n",
    "                ids1 = idmin\n",
    "\n",
    "                sub_Sigma = Sigma2[np.ix_(ids1, ids1)]\n",
    "                U1 = np.linalg.cholesky(sub_Sigma)\n",
    "                G_pre.append(np.mean(np.min(mu[ids1] + (U1 @ z_samples.T).T, axis=1)))\n",
    "            \n",
    "            # Save results\n",
    "            with open(csv_path, 'a') as f:\n",
    "                f.write(','.join([str(repeat)] + [f'{x:.6f}' for x in np.array(G)-G_real]) + '\\n')\n",
    "            with open(csv_path1, 'a') as f:\n",
    "                f.write(','.join([str(repeat)] + [f'{x:.6f}' for x in np.array(G_pre)-G_real]) + '\\n')\n",
    "\n",
    "        with open(detail_csv_path, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['Algorithm', 'Repetition', 'Iteration', 'Selected_Modules', 'Expected_Minimum'])\n",
    "            writer.writerows(detail_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31bcdd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutdown scheduled for Tue 2025-11-18 12:58:02 CST, use 'shutdown -c' to cancel.\n"
     ]
    }
   ],
   "source": [
    "!shutdown -h +1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd80efa",
   "metadata": {},
   "source": [
    "* worst: [31, 34, 29, 40, 24, 36, 43, 35]\n",
    "* random: [1, 20, 47, 35, 7, 8, 17, 37]\n",
    "* best: [10, 11, 48, 47, 9, 45, 43, 34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3457bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import multivariate_normal\n",
    "from util.data_generate import *\n",
    "from util.methods import *\n",
    "import csv\n",
    "#best\n",
    "p = 50\n",
    "m=16\n",
    "betas = ['smallest','cluster','dynamic']\n",
    "seed, J, n_iter, num_repeats = 1, 10000, 150, 30\n",
    "np.random.seed(seed=seed)\n",
    "Sigma1 = np.loadtxt('Data_generate/Sigma1.txt')\n",
    "Sigma1 = Sigma1 * 4\n",
    "\n",
    "Sigma2 = np.loadtxt('Data_generate/group_cov.txt')\n",
    "std2 = np.sqrt(np.diag(Sigma2))\n",
    "R2 = Sigma2 / np.outer(std2, std2)\n",
    "mu = np.loadtxt('Data_generate/mu.txt')\n",
    "\n",
    "#U, ids1 = improvement(p, m, mu, std2, R2, Sigma2, J=J)\n",
    "ids1 = [11, 34, 1, 35, 9, 28, 0, 7, 31, 29, 3, 2, 4, 33, 32, 30]\n",
    "ids2 = [4,11,29,28,12,7,32,0,31,35,30,3,34,2,1,33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = cyclic_multstart(p, m, mu, std2, R2, Sigma2, J=J, mult = 100)\n",
    "ids2 = A[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_samples2 = np.random.randn(1000000, m)\n",
    "ids1 = ids1\n",
    "sub_Sigma = Sigma2[np.ix_(ids1, ids1)]\n",
    "U1 = np.linalg.cholesky(sub_Sigma)\n",
    "e1 = (np.mean(np.min(mu[ids1] + (U1 @ z_samples2.T).T, axis=1)))\n",
    "e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc38ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids2 = ids2\n",
    "sub_Sigma = Sigma2[np.ix_(ids2, ids2)]\n",
    "U2 = np.linalg.cholesky(sub_Sigma)\n",
    "e2 = (np.mean(np.min(mu[ids2] + (U2 @ z_samples2.T).T, axis=1)))\n",
    "e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.calculate import MultivariateNormalMinimum\n",
    "# 初始化\n",
    "calculator = MultivariateNormalMinimum(mu[ids1], Sigma2[np.ix_(ids1, ids1)])\n",
    "\n",
    "# 简单计算\n",
    "for i in range(30):\n",
    "    result_exact = calculator.compute_R(max_dim=21, n_samples=100000,seed = i)\n",
    "    print(result_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3293305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val, lower, upper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db7902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "99/99.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
