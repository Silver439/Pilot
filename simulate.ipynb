{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c0c858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:35<00:00,  3.17s/it]\n",
      "100%|██████████| 30/30 [01:36<00:00,  3.20s/it]\n",
      "100%|██████████| 30/30 [07:14<00:00, 14.49s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import multivariate_normal\n",
    "from util.data_generate import *\n",
    "from util.methods import *\n",
    "import csv\n",
    "#worst\n",
    "p = 50\n",
    "betas = ['smallest','cluster','dynamic']\n",
    "seed, J, n_iter, num_repeats = 1, 10000, 150, 30\n",
    "np.random.seed(seed=seed)\n",
    "Sigma1 = np.loadtxt('Data_generate/Sigma1.txt')\n",
    "Sigma1 = Sigma1 * 4\n",
    "\n",
    "Sigma2 = np.loadtxt('Data_generate/group_cov.txt')\n",
    "std2 = np.sqrt(np.diag(Sigma2))\n",
    "R2 = Sigma2 / np.outer(std2, std2)\n",
    "mu = np.loadtxt('Data_generate/mu.txt')\n",
    "\n",
    "for m in [16,]:\n",
    "    U3, ids3 = SAA(p, m, mu, std2, R2, Sigma2, J=J)\n",
    "    z_samples = np.random.randn(J*10, m)\n",
    "    G_real = np.mean(np.min(mu[ids3] + (U3 @ z_samples.T).T, axis=1))\n",
    "    cluster_labels = cluster_subjects(R2, n_clusters=m, method='average')\n",
    "    for beta in betas:\n",
    "\n",
    "        csv_path = f'{p}_{m}_{beta}.csv'\n",
    "        csv_path1 = f'{p}_{m}_{beta}_pre.csv'\n",
    "\n",
    "        # Initialize CSV\n",
    "        with open(csv_path, 'w') as f:\n",
    "            f.write(','.join(['Repetition'] + [f'Step_{i}' for i in range(1, n_iter+1)]) + '\\n')\n",
    "        with open(csv_path1, 'w') as f:\n",
    "            f.write(','.join(['Repetition'] + [f'Step_{i}' for i in range(1, n_iter+1)]) + '\\n')\n",
    "\n",
    "        for repeat in tqdm(range(num_repeats)):\n",
    "            # Initial setup\n",
    "            seed = seed + repeat\n",
    "            \n",
    "            # Initialize variables\n",
    "            mu_0 = np.full(p, 70)\n",
    "            mu_hat, var_hat, obs_num = np.zeros(p), np.ones(p), np.zeros(p)\n",
    "            \n",
    "            # Initial observation\n",
    "            N_0 = math.ceil(p / m)\n",
    "            for i in range(N_0):\n",
    "                ids = efficient_initialization(p, m, obs_num, mu_0, std2, R2, Sigma2, J)\n",
    "                obs_num[ids] += 1\n",
    "                indices = ids.copy()\n",
    "                obs = np.random.multivariate_normal(mu[ids], Sigma2[np.ix_(ids, ids)])\n",
    "                X_n = ids.copy()\n",
    "                \n",
    "                # Update estimates\n",
    "                Gamma = Sigma2[np.ix_(ids, ids)]\n",
    "                inv_mat = np.linalg.inv(Sigma1[np.ix_(ids, ids)] + Gamma)\n",
    "                delta = (obs - mu_0[ids]).reshape(-1, 1)\n",
    "                \n",
    "                COV_x = Sigma1[:, ids]\n",
    "                adjustments = (COV_x @ inv_mat @ delta).flatten()\n",
    "                mu_hat = mu_0 + adjustments\n",
    "                adjustments = np.diag(COV_x @ inv_mat @ COV_x.T)\n",
    "                var_hat = np.diag(Sigma1) - adjustments\n",
    "                \n",
    "            # Main loop\n",
    "            G = [] #用于计算累积遗憾\n",
    "            G_pre = [] \n",
    "            for t in range(N_0+1, n_iter+1):\n",
    "                if beta == 'dynamic':\n",
    "                    dynamic_beta = np.sqrt(6 * np.log(t) / np.maximum(obs_num, 1))\n",
    "                    U, ids = improvement(p, m, mu_hat - dynamic_beta * np.sqrt(var_hat), std2, R2, Sigma2, J=J)\n",
    "                elif beta == 'cluster': \n",
    "                    ids = find_min_mu_in_clusters(mu_hat, cluster_labels)\n",
    "                    sub_Sigma_cluster = Sigma2[np.ix_(ids, ids)]\n",
    "                    U = np.linalg.cholesky(sub_Sigma_cluster) \n",
    "                else:\n",
    "                    ids = np.argsort(mu_hat)[:m]\n",
    "                    sub_Sigma_smallest = Sigma2[np.ix_(ids, ids)]\n",
    "                    U = np.linalg.cholesky(sub_Sigma_smallest) \n",
    "                obs_num[ids] += 1\n",
    "                indices = np.vstack((indices, ids))\n",
    "                \n",
    "                newobs = np.random.multivariate_normal(mu[ids], Sigma2[np.ix_(ids, ids)])\n",
    "                X_n, obs = update_subject_stats(obs_num, X_n, obs, ids, newobs)\n",
    "                \n",
    "                # Update Gamma matrix\n",
    "                len_Xn = len(X_n)\n",
    "                Gamma = np.zeros((len_Xn, len_Xn))\n",
    "                for i in range(len_Xn):\n",
    "                    for j in range(i, len_Xn):\n",
    "                        count = np.sum((indices == X_n[i]).any(1) & (indices == X_n[j]).any(1))\n",
    "                        Gamma[i,j] = Sigma2[X_n[i],X_n[j]] * count / (obs_num[X_n[i]] * obs_num[X_n[j]])\n",
    "                Gamma += Gamma.T\n",
    "                np.fill_diagonal(Gamma, np.diag(Gamma)/2)\n",
    "                \n",
    "                # Update estimates\n",
    "                COV_XX = Sigma1[np.ix_(X_n, X_n)]\n",
    "                inv_mat = np.linalg.inv(COV_XX + Gamma)\n",
    "                delta = (obs - mu_0[X_n]).reshape(-1, 1)\n",
    "                \n",
    "                COV_x = Sigma1[:, X_n]\n",
    "                adjustments = (COV_x @ inv_mat @ delta).flatten()\n",
    "                mu_hat = mu_0 + adjustments\n",
    "                adjustments = np.diag(COV_x @ inv_mat @ COV_x.T)\n",
    "                var_hat = np.diag(Sigma1) - adjustments\n",
    "\n",
    "                # Calculate G\n",
    "                z_samples = np.random.randn(J*10, m)\n",
    "                G.append(np.mean(np.min(mu[ids] + (U @ z_samples.T).T, axis=1)))\n",
    "\n",
    "                Gmin = 1000\n",
    "                idmin = []\n",
    "                z_samples2 = np.random.randn(J, m)\n",
    "                for id in indices:\n",
    "                    sub_Sigma = Sigma2[np.ix_(id, id)]\n",
    "                    B = np.linalg.cholesky(sub_Sigma)\n",
    "                    Gtemp = np.mean(np.min(mu_hat[id] + (B @ z_samples2.T).T, axis=1))\n",
    "                    if Gtemp < Gmin:\n",
    "                        idmin = id.copy()\n",
    "                        Gmin = Gtemp\n",
    "                ids1 = idmin\n",
    "\n",
    "                sub_Sigma = Sigma2[np.ix_(ids1, ids1)]\n",
    "                U1 = np.linalg.cholesky(sub_Sigma)\n",
    "                G_pre.append(np.mean(np.min(mu[ids1] + (U1 @ z_samples.T).T, axis=1)))\n",
    "            \n",
    "            # Save results\n",
    "            with open(csv_path, 'a') as f:\n",
    "                f.write(','.join([str(repeat)] + [f'{x:.6f}' for x in np.array(G)-G_real]) + '\\n')\n",
    "            with open(csv_path1, 'a') as f:\n",
    "                f.write(','.join([str(repeat)] + [f'{x:.6f}' for x in np.array(G_pre)-G_real]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd0a1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接计算的U2:\n",
      "[[10.48826473  0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 4.92991246  9.71229211  0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 5.57206626  3.49414636  8.3294753   0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 5.37311514  2.89299131  0.35515183  7.85787109  0.          0.\n",
      "   0.          0.        ]\n",
      " [ 5.14522892  3.64402001  1.14462796  1.70193345  7.99156561  0.\n",
      "   0.          0.        ]\n",
      " [ 4.53690112  1.86199884  3.52416219  2.06202082 -1.06996252  7.02231399\n",
      "   0.          0.        ]\n",
      " [ 3.69404921  1.32876376  2.88244327  1.84944091  2.20537299  1.92655792\n",
      "   7.25198793  0.        ]\n",
      " [-0.2192213   0.67137229  0.4332055  -0.77437802  0.419542    0.2004193\n",
      "   0.84546034  8.59466703]]\n",
      "\n",
      "修正后的更新结果:\n",
      "[[10.48826473  0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 4.92991246  9.71229211  0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 5.57206626  3.49414636  8.3294753   0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 5.37311514  2.89299131  0.35515183  7.85787109  0.          0.\n",
      "   0.          0.        ]\n",
      " [ 5.14522892  3.64402001  1.14462796  1.70193345  7.99156561  0.\n",
      "   0.          0.        ]\n",
      " [ 4.53690112  1.86199884  3.52416219  2.06202082 -1.06996252  7.02231399\n",
      "   0.          0.        ]\n",
      " [ 3.69404921  1.32876376  2.88244327  1.84944091  2.20537299  1.92655792\n",
      "   7.25198793  0.        ]\n",
      " [-0.2192213   0.67137229  0.4332055  -0.77437802  0.419542    0.2004193\n",
      "   0.84546034  8.59466703]]\n",
      "\n",
      "两者是否相同? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import multivariate_normal\n",
    "from util.data_generate import *\n",
    "from util.methods import *\n",
    "import csv\n",
    "# 你的具体例子\n",
    "ids1 = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "ids2 = [1, 2, 3, 4, 5, 6, 7, 11]  # 只有最后一个元素不同\n",
    "Sigma2 = np.loadtxt('Data_generate/group_cov.txt')\n",
    "\n",
    "# 提取子矩阵\n",
    "A = Sigma2[np.ix_(ids1, ids1)]\n",
    "B = Sigma2[np.ix_(ids2, ids2)]\n",
    "\n",
    "# 计算旧的Cholesky分解\n",
    "U1 = np.linalg.cholesky(A)\n",
    "\n",
    "# 正确的方法：从变化位置开始更新所有后续行\n",
    "U2_corrected = cholesky_update(U1, B)\n",
    "\n",
    "# 验证\n",
    "U2_full = np.linalg.cholesky(B)\n",
    "\n",
    "print(\"直接计算的U2:\")\n",
    "print(U2_full)\n",
    "print(\"\\n修正后的更新结果:\")\n",
    "print(U2_corrected)\n",
    "print(\"\\n两者是否相同?\", np.allclose(U2_full, U2_corrected, atol=1e-10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
